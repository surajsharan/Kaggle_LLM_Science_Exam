{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3222c94-0add-4561-8803-792d0af1a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from typing import Optional, Union\n",
    "import pandas as pd, numpy as np, torch\n",
    "from datasets import Dataset\n",
    "from dataclasses import dataclass\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5fc3f54-1ead-42aa-9965-70d00b1b1d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5968a5c8-9762-4c87-9e46-4e30a5b462ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "VER=1\n",
    "# TRAIN WITH SUBSET OF 60K\n",
    "NUM_TRAIN_SAMPLES = 1024\n",
    "# PARAMETER EFFICIENT FINE TUNING\n",
    "# PEFT REQUIRES 1XP100 GPU NOT 2XT4\n",
    "USE_PEFT = False\n",
    "# NUMBER OF LAYERS TO FREEZE \n",
    "# DEBERTA LARGE HAS TOTAL OF 24 LAYERS\n",
    "FREEZE_LAYERS = 0\n",
    "# BOOLEAN TO FREEZE EMBEDDINGS\n",
    "FREEZE_EMBEDDINGS = True\n",
    "# LENGTH OF CONTEXT PLUS QUESTION ANSWER\n",
    "MAX_INPUT = 1496\n",
    "# HUGGING FACE MODEL\n",
    "MODEL = 'microsoft/deberta-v3-large'\n",
    "model_name = MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5e1e762-4233-4a08-af63-9b8dedd35218",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv('input_data/validation_data/master_validation_data_article_context.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b4c67e-bdd1-4071-917c-77738f78519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_gpt = pd.read_csv('input_data/validation_data/eval300_gpt4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee4abe92-a2c1-41e1-9dda-784070f9b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_gpt['prompt_answer'] = eval_gpt.apply(lambda row: ''.join(row['prompt'] + row['answer']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c6ff4c6-3c88-4b2f-a5aa-420da4e280d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid['prompt_answer'] = df_valid.apply(lambda row: ''.join(row['prompt'] + row['answer']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddcd87ba-17cc-4356-9ee8-780f62c98eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_valid.merge(eval_gpt[['answer','prompt_answer','gpt4']], on=['prompt_answer'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e928762-5be5-4c18-8eb8-9bd52a17d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditionally update the gpt4 column\n",
    "df_merge['answer'] = np.where(df_merge['gpt4'].isna(), df_merge['answer_x'], df_merge['gpt4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b5e4516-47af-4328-ad88-ac6bf073364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load = pd.read_csv('base/validation_data_mistral_LORA_predicted_2percent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8105baec-a68e-43e9-be96-ab5b6970e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_load['deberta_choice_1'] = df_load['prediction'].str[0]\n",
    "df_load['deberta_choice_2'] = df_load['prediction'].str[2]\n",
    "df_load['deberta_choice_3'] = df_load['prediction'].str[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "52730704-9854-4512-bf3b-75af94fd81fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     1077\n",
       "False     193\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_load['deberta_choice_1'] ==df_load['answer']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "318eefb7-5876-4a68-b5e9-5b4290cf29df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_false = df_load[ df_load.answer != df_load.deberta_choice_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d098839c-48fa-464b-9aa2-4b4421840c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>instruction</th>\n",
       "      <th>prediction</th>\n",
       "      <th>logits</th>\n",
       "      <th>deberta_choice_1</th>\n",
       "      <th>deberta_choice_2</th>\n",
       "      <th>deberta_choice_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What does a diffusion-limited enzyme represent...</td>\n",
       "      <td>An intrinsic, physical constraint</td>\n",
       "      <td>A maximum peak height in the fitness landscape</td>\n",
       "      <td>An evolutionary limitation</td>\n",
       "      <td>A chemical limitation</td>\n",
       "      <td>A diffusion limitation</td>\n",
       "      <td>B</td>\n",
       "      <td>-A diffusion-limited enzyme catalyses a reacti...</td>\n",
       "      <td>What does a diffusion-limited enzyme represent...</td>\n",
       "      <td>A B E</td>\n",
       "      <td>[(array(0.681964, dtype=float32), 'A'), (array...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What is the height at which mountaineers are m...</td>\n",
       "      <td>6,000 feet</td>\n",
       "      <td>9,000 feet</td>\n",
       "      <td>12,000 feet</td>\n",
       "      <td>18,000 feet</td>\n",
       "      <td>15,000 feet</td>\n",
       "      <td>B</td>\n",
       "      <td>-Altitude sickness can first occur at 1,500 me...</td>\n",
       "      <td>What is the height at which mountaineers are m...</td>\n",
       "      <td>D C B</td>\n",
       "      <td>[(array(0.04697393, dtype=float32), 'A'), (arr...</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Which eukaryotic cell cycle event is missing i...</td>\n",
       "      <td>cell growth</td>\n",
       "      <td>DNA duplication</td>\n",
       "      <td>karyokinesis</td>\n",
       "      <td>cytokinesis</td>\n",
       "      <td>cell growth</td>\n",
       "      <td>C</td>\n",
       "      <td>-Cytokinesis largely resembles the prokaryotic...</td>\n",
       "      <td>Which eukaryotic cell cycle event is missing i...</td>\n",
       "      <td>B C D</td>\n",
       "      <td>[(array(0.02956403, dtype=float32), 'A'), (arr...</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>What is the significant characteristic of Gior...</td>\n",
       "      <td>Giordano Bruno (crater) displays an unusual pa...</td>\n",
       "      <td>Giordano Bruno (crater) has a higher albedo th...</td>\n",
       "      <td>The outer rim of Giordano Bruno (crater) is pa...</td>\n",
       "      <td>Some of the ejecta from Giordano Bruno (crater...</td>\n",
       "      <td>Giordano Bruno (crater) appears at the center ...</td>\n",
       "      <td>B</td>\n",
       "      <td>-Impact craters generally have a rim with ejec...</td>\n",
       "      <td>What is the significant characteristic of Gior...</td>\n",
       "      <td>E D B</td>\n",
       "      <td>[(array(0.01559149, dtype=float32), 'A'), (arr...</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Which circulation picks up oxygen for cellular...</td>\n",
       "      <td>pulmonary</td>\n",
       "      <td>interlobular</td>\n",
       "      <td>respiratory</td>\n",
       "      <td>bronchial</td>\n",
       "      <td>interlobular</td>\n",
       "      <td>C</td>\n",
       "      <td>-In vertebrates, oxygen is taken into the body...</td>\n",
       "      <td>Which circulation picks up oxygen for cellular...</td>\n",
       "      <td>A C D</td>\n",
       "      <td>[(array(0.47210026, dtype=float32), 'A'), (arr...</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>1241</td>\n",
       "      <td>What are permutation-inversion groups?</td>\n",
       "      <td>Permutation-inversion groups are groups of sym...</td>\n",
       "      <td>Permutation-inversion groups are groups of sym...</td>\n",
       "      <td>Permutation-inversion groups are groups of sym...</td>\n",
       "      <td>Permutation-inversion groups are groups of sym...</td>\n",
       "      <td>Permutation-inversion groups are groups of sym...</td>\n",
       "      <td>E</td>\n",
       "      <td>-Symmetry operations, point groups and permuta...</td>\n",
       "      <td>What are permutation-inversion groups? A: Perm...</td>\n",
       "      <td>B E A</td>\n",
       "      <td>[(array(0.06476416, dtype=float32), 'A'), (arr...</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>1246</td>\n",
       "      <td>What is the difference between redshift due to...</td>\n",
       "      <td>Redshift due to the expansion of the universe ...</td>\n",
       "      <td>Redshift due to the expansion of the universe ...</td>\n",
       "      <td>There is no difference between redshift due to...</td>\n",
       "      <td>Redshift due to the expansion of the universe ...</td>\n",
       "      <td>Redshift due to the expansion of the universe ...</td>\n",
       "      <td>D</td>\n",
       "      <td>-Redshift is also used to measure the expansio...</td>\n",
       "      <td>What is the difference between redshift due to...</td>\n",
       "      <td>E A D</td>\n",
       "      <td>[(array(0.2822599, dtype=float32), 'A'), (arra...</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>1248</td>\n",
       "      <td>What is the reason for heating metals to a tem...</td>\n",
       "      <td>To prevent the grains of solution from growing...</td>\n",
       "      <td>To increase the size of the grains of solution...</td>\n",
       "      <td>To prevent the grains of solution from growing...</td>\n",
       "      <td>To prevent the grains of solution from growing...</td>\n",
       "      <td>To increase the size of the grains of solution...</td>\n",
       "      <td>C</td>\n",
       "      <td>-Metallic materials consist of a microstructur...</td>\n",
       "      <td>What is the reason for heating metals to a tem...</td>\n",
       "      <td>A C B</td>\n",
       "      <td>[(array(0.3446145, dtype=float32), 'A'), (arra...</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>1257</td>\n",
       "      <td>What is the explanation for the effective supe...</td>\n",
       "      <td>Two different color charges close together app...</td>\n",
       "      <td>Two different color charges close together app...</td>\n",
       "      <td>Two different color charges close together app...</td>\n",
       "      <td>Two different color charges close together app...</td>\n",
       "      <td>Two different color charges close together app...</td>\n",
       "      <td>A</td>\n",
       "      <td>-Nonetheless, color-charged particles may comb...</td>\n",
       "      <td>What is the explanation for the effective supe...</td>\n",
       "      <td>D A E</td>\n",
       "      <td>[(array(0.23341925, dtype=float32), 'A'), (arr...</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>1260</td>\n",
       "      <td>What is the Heisenberg uncertainty principle a...</td>\n",
       "      <td>The Heisenberg uncertainty principle states th...</td>\n",
       "      <td>The Heisenberg uncertainty principle states th...</td>\n",
       "      <td>The Heisenberg uncertainty principle states th...</td>\n",
       "      <td>The Heisenberg uncertainty principle states th...</td>\n",
       "      <td>The Heisenberg uncertainty principle states th...</td>\n",
       "      <td>E</td>\n",
       "      <td>-In quantum mechanics, angular momentum (like ...</td>\n",
       "      <td>What is the Heisenberg uncertainty principle a...</td>\n",
       "      <td>D E A</td>\n",
       "      <td>[(array(0.02143571, dtype=float32), 'A'), (arr...</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             prompt  \\\n",
       "0        0  What does a diffusion-limited enzyme represent...   \n",
       "4        4  What is the height at which mountaineers are m...   \n",
       "8        8  Which eukaryotic cell cycle event is missing i...   \n",
       "10      10  What is the significant characteristic of Gior...   \n",
       "12      12  Which circulation picks up oxygen for cellular...   \n",
       "...    ...                                                ...   \n",
       "1241  1241             What are permutation-inversion groups?   \n",
       "1246  1246  What is the difference between redshift due to...   \n",
       "1248  1248  What is the reason for heating metals to a tem...   \n",
       "1257  1257  What is the explanation for the effective supe...   \n",
       "1260  1260  What is the Heisenberg uncertainty principle a...   \n",
       "\n",
       "                                                      A  \\\n",
       "0                     An intrinsic, physical constraint   \n",
       "4                                            6,000 feet   \n",
       "8                                           cell growth   \n",
       "10    Giordano Bruno (crater) displays an unusual pa...   \n",
       "12                                            pulmonary   \n",
       "...                                                 ...   \n",
       "1241  Permutation-inversion groups are groups of sym...   \n",
       "1246  Redshift due to the expansion of the universe ...   \n",
       "1248  To prevent the grains of solution from growing...   \n",
       "1257  Two different color charges close together app...   \n",
       "1260  The Heisenberg uncertainty principle states th...   \n",
       "\n",
       "                                                      B  \\\n",
       "0        A maximum peak height in the fitness landscape   \n",
       "4                                            9,000 feet   \n",
       "8                                       DNA duplication   \n",
       "10    Giordano Bruno (crater) has a higher albedo th...   \n",
       "12                                         interlobular   \n",
       "...                                                 ...   \n",
       "1241  Permutation-inversion groups are groups of sym...   \n",
       "1246  Redshift due to the expansion of the universe ...   \n",
       "1248  To increase the size of the grains of solution...   \n",
       "1257  Two different color charges close together app...   \n",
       "1260  The Heisenberg uncertainty principle states th...   \n",
       "\n",
       "                                                      C  \\\n",
       "0                            An evolutionary limitation   \n",
       "4                                           12,000 feet   \n",
       "8                                          karyokinesis   \n",
       "10    The outer rim of Giordano Bruno (crater) is pa...   \n",
       "12                                          respiratory   \n",
       "...                                                 ...   \n",
       "1241  Permutation-inversion groups are groups of sym...   \n",
       "1246  There is no difference between redshift due to...   \n",
       "1248  To prevent the grains of solution from growing...   \n",
       "1257  Two different color charges close together app...   \n",
       "1260  The Heisenberg uncertainty principle states th...   \n",
       "\n",
       "                                                      D  \\\n",
       "0                                 A chemical limitation   \n",
       "4                                           18,000 feet   \n",
       "8                                           cytokinesis   \n",
       "10    Some of the ejecta from Giordano Bruno (crater...   \n",
       "12                                            bronchial   \n",
       "...                                                 ...   \n",
       "1241  Permutation-inversion groups are groups of sym...   \n",
       "1246  Redshift due to the expansion of the universe ...   \n",
       "1248  To prevent the grains of solution from growing...   \n",
       "1257  Two different color charges close together app...   \n",
       "1260  The Heisenberg uncertainty principle states th...   \n",
       "\n",
       "                                                      E answer  \\\n",
       "0                                A diffusion limitation      B   \n",
       "4                                           15,000 feet      B   \n",
       "8                                           cell growth      C   \n",
       "10    Giordano Bruno (crater) appears at the center ...      B   \n",
       "12                                         interlobular      C   \n",
       "...                                                 ...    ...   \n",
       "1241  Permutation-inversion groups are groups of sym...      E   \n",
       "1246  Redshift due to the expansion of the universe ...      D   \n",
       "1248  To increase the size of the grains of solution...      C   \n",
       "1257  Two different color charges close together app...      A   \n",
       "1260  The Heisenberg uncertainty principle states th...      E   \n",
       "\n",
       "                                                context  \\\n",
       "0     -A diffusion-limited enzyme catalyses a reacti...   \n",
       "4     -Altitude sickness can first occur at 1,500 me...   \n",
       "8     -Cytokinesis largely resembles the prokaryotic...   \n",
       "10    -Impact craters generally have a rim with ejec...   \n",
       "12    -In vertebrates, oxygen is taken into the body...   \n",
       "...                                                 ...   \n",
       "1241  -Symmetry operations, point groups and permuta...   \n",
       "1246  -Redshift is also used to measure the expansio...   \n",
       "1248  -Metallic materials consist of a microstructur...   \n",
       "1257  -Nonetheless, color-charged particles may comb...   \n",
       "1260  -In quantum mechanics, angular momentum (like ...   \n",
       "\n",
       "                                            instruction prediction  \\\n",
       "0     What does a diffusion-limited enzyme represent...      A B E   \n",
       "4     What is the height at which mountaineers are m...      D C B   \n",
       "8     Which eukaryotic cell cycle event is missing i...      B C D   \n",
       "10    What is the significant characteristic of Gior...      E D B   \n",
       "12    Which circulation picks up oxygen for cellular...      A C D   \n",
       "...                                                 ...        ...   \n",
       "1241  What are permutation-inversion groups? A: Perm...      B E A   \n",
       "1246  What is the difference between redshift due to...      E A D   \n",
       "1248  What is the reason for heating metals to a tem...      A C B   \n",
       "1257  What is the explanation for the effective supe...      D A E   \n",
       "1260  What is the Heisenberg uncertainty principle a...      D E A   \n",
       "\n",
       "                                                 logits deberta_choice_1  \\\n",
       "0     [(array(0.681964, dtype=float32), 'A'), (array...                A   \n",
       "4     [(array(0.04697393, dtype=float32), 'A'), (arr...                D   \n",
       "8     [(array(0.02956403, dtype=float32), 'A'), (arr...                B   \n",
       "10    [(array(0.01559149, dtype=float32), 'A'), (arr...                E   \n",
       "12    [(array(0.47210026, dtype=float32), 'A'), (arr...                A   \n",
       "...                                                 ...              ...   \n",
       "1241  [(array(0.06476416, dtype=float32), 'A'), (arr...                B   \n",
       "1246  [(array(0.2822599, dtype=float32), 'A'), (arra...                E   \n",
       "1248  [(array(0.3446145, dtype=float32), 'A'), (arra...                A   \n",
       "1257  [(array(0.23341925, dtype=float32), 'A'), (arr...                D   \n",
       "1260  [(array(0.02143571, dtype=float32), 'A'), (arr...                D   \n",
       "\n",
       "     deberta_choice_2 deberta_choice_3  \n",
       "0                   B                E  \n",
       "4                   C                B  \n",
       "8                   C                D  \n",
       "10                  D                B  \n",
       "12                  C                D  \n",
       "...               ...              ...  \n",
       "1241                E                A  \n",
       "1246                A                D  \n",
       "1248                C                B  \n",
       "1257                A                E  \n",
       "1260                E                A  \n",
       "\n",
       "[193 rows x 15 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de214c42-16ce-4152-8c29-29118f56af65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925a3b3a-5ac2-44fc-b3dc-092915178bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dd9a8772-fac5-46e6-a4f5-261c3faeb8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.to_csv('input_data/validation_data/master_validation_data_article_context_corrected.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d230e844-0ffd-43d4-839e-a207995c5fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_merge['prompt_answer'], df_merge['answer_y'], df_merge['gpt4'],df_merge['answer_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca81b52c-2296-4e6b-b9a8-266a5ac2958e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = df_merge[~df_merge['answer_y'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d3defb1-a5d3-49d3-b9dc-f4f6d355c2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    300\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(eval_df['answer']==eval_df['gpt4']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1bb56cbc-6094-4d8a-9bd7-fddccd7f1504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>answer_x</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt_answer</th>\n",
       "      <th>answer_y</th>\n",
       "      <th>gpt4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>771</td>\n",
       "      <td>What is the method of transcription in the lif...</td>\n",
       "      <td>RNA-templated transcription is the method of t...</td>\n",
       "      <td>Transcription occurs through a unique mechanis...</td>\n",
       "      <td>Reverse transcription is the method of transcr...</td>\n",
       "      <td>DNA-templated transcription is the method of t...</td>\n",
       "      <td>Transcription does not occur in the life cycle...</td>\n",
       "      <td>D</td>\n",
       "      <td>-There are three different replication systems...</td>\n",
       "      <td>What is the method of transcription in the lif...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>772</td>\n",
       "      <td>What is the role of the viral fiber glycoprote...</td>\n",
       "      <td>The viral fiber glycoproteins are involved in ...</td>\n",
       "      <td>The viral fiber glycoproteins code for 40 prot...</td>\n",
       "      <td>The viral fiber glycoproteins are responsible ...</td>\n",
       "      <td>The viral fiber glycoproteins mediate endocyto...</td>\n",
       "      <td>The viral fiber glycoproteins are responsible ...</td>\n",
       "      <td>D</td>\n",
       "      <td>-ASFV is a large (175–215 nm), icosahedral, do...</td>\n",
       "      <td>What is the role of the viral fiber glycoprote...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>773</td>\n",
       "      <td>What is the significance of the faint Hα emiss...</td>\n",
       "      <td>The emission lines indicate that 3 Geminorum i...</td>\n",
       "      <td>The emission lines indicate that 3 Geminorum i...</td>\n",
       "      <td>The emission lines indicate that 3 Geminorum i...</td>\n",
       "      <td>The emission lines indicate that 3 Geminorum i...</td>\n",
       "      <td>The emission lines indicate that 3 Geminorum i...</td>\n",
       "      <td>A</td>\n",
       "      <td>-Single antenna detections Radio observations ...</td>\n",
       "      <td>What is the significance of the faint Hα emiss...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>774</td>\n",
       "      <td>What is the significance of the pedicellariae ...</td>\n",
       "      <td>They are used for climbing on corals.</td>\n",
       "      <td>They resemble the traps of the Venus fly trap ...</td>\n",
       "      <td>They are covered by short and stout spines.</td>\n",
       "      <td>They are found on the central disc of the sea ...</td>\n",
       "      <td>They are a characteristic feature of the Gonia...</td>\n",
       "      <td>B</td>\n",
       "      <td>-Structure The three basic segments of the typ...</td>\n",
       "      <td>What is the significance of the pedicellariae ...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>775</td>\n",
       "      <td>What is the role of the microprocessor complex...</td>\n",
       "      <td>The microprocessor complex is responsible for ...</td>\n",
       "      <td>The microprocessor complex is responsible for ...</td>\n",
       "      <td>The microprocessor complex is involved in the ...</td>\n",
       "      <td>The microprocessor complex is involved in the ...</td>\n",
       "      <td>The microprocessor complex is responsible for ...</td>\n",
       "      <td>A</td>\n",
       "      <td>-The microprocessor complex is a protein compl...</td>\n",
       "      <td>What is the role of the microprocessor complex...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>1066</td>\n",
       "      <td>What is the significance of the anti-de Sitter...</td>\n",
       "      <td>The AdS/CFT correspondence is a conjectured re...</td>\n",
       "      <td>The AdS/CFT correspondence provides a non-pert...</td>\n",
       "      <td>The AdS/CFT correspondence represents a major ...</td>\n",
       "      <td>The AdS/CFT correspondence is a strong-weak du...</td>\n",
       "      <td>The AdS/CFT correspondence was first proposed ...</td>\n",
       "      <td>C</td>\n",
       "      <td>-In theoretical physics, anti-de Sitter/confor...</td>\n",
       "      <td>What is the significance of the anti-de Sitter...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>1067</td>\n",
       "      <td>What is the branch of physics that seeks to de...</td>\n",
       "      <td>String theory</td>\n",
       "      <td>Quantum gravity</td>\n",
       "      <td>AdS/CFT correspondence</td>\n",
       "      <td>General relativity</td>\n",
       "      <td>M-theory</td>\n",
       "      <td>B</td>\n",
       "      <td>-Quantum gravity and strings Current understan...</td>\n",
       "      <td>What is the branch of physics that seeks to de...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>1068</td>\n",
       "      <td>What is the AdS/CFT correspondence according t...</td>\n",
       "      <td>The AdS/CFT correspondence is a relationship b...</td>\n",
       "      <td>The AdS/CFT correspondence is the theory that ...</td>\n",
       "      <td>The AdS/CFT correspondence is a dictionary tha...</td>\n",
       "      <td>The AdS/CFT correspondence is the equivalence ...</td>\n",
       "      <td>The AdS/CFT correspondence is a mathematical c...</td>\n",
       "      <td>D</td>\n",
       "      <td>-In theoretical physics, anti-de Sitter/confor...</td>\n",
       "      <td>What is the AdS/CFT correspondence according t...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>1069</td>\n",
       "      <td>What is the purpose of superstring theory acco...</td>\n",
       "      <td>To explain the behavior of fundamental particl...</td>\n",
       "      <td>To explain the behavior of large-scale structu...</td>\n",
       "      <td>To describe the four fundamental forces acting...</td>\n",
       "      <td>To harmonize the theory of general relativity ...</td>\n",
       "      <td>To eliminate the infinities in quantum field t...</td>\n",
       "      <td>A</td>\n",
       "      <td>-Superstring theory is an attempt to explain a...</td>\n",
       "      <td>What is the purpose of superstring theory acco...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>1070</td>\n",
       "      <td>What is the role of T-duality in string/M-theory?</td>\n",
       "      <td>T-duality reveals the existence of mirror symm...</td>\n",
       "      <td>T-duality transforms compact dimensions of rad...</td>\n",
       "      <td>T-duality unifies gauge and gravity interactio...</td>\n",
       "      <td>T-duality exchanges momentum modes for winding...</td>\n",
       "      <td>T-duality explains the compactification of the...</td>\n",
       "      <td>A</td>\n",
       "      <td>-This transformation between the two 10-dimens...</td>\n",
       "      <td>What is the role of T-duality in string/M-theo...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             prompt  \\\n",
       "771    771  What is the method of transcription in the lif...   \n",
       "772    772  What is the role of the viral fiber glycoprote...   \n",
       "773    773  What is the significance of the faint Hα emiss...   \n",
       "774    774  What is the significance of the pedicellariae ...   \n",
       "775    775  What is the role of the microprocessor complex...   \n",
       "...    ...                                                ...   \n",
       "1066  1066  What is the significance of the anti-de Sitter...   \n",
       "1067  1067  What is the branch of physics that seeks to de...   \n",
       "1068  1068  What is the AdS/CFT correspondence according t...   \n",
       "1069  1069  What is the purpose of superstring theory acco...   \n",
       "1070  1070  What is the role of T-duality in string/M-theory?   \n",
       "\n",
       "                                                      A  \\\n",
       "771   RNA-templated transcription is the method of t...   \n",
       "772   The viral fiber glycoproteins are involved in ...   \n",
       "773   The emission lines indicate that 3 Geminorum i...   \n",
       "774               They are used for climbing on corals.   \n",
       "775   The microprocessor complex is responsible for ...   \n",
       "...                                                 ...   \n",
       "1066  The AdS/CFT correspondence is a conjectured re...   \n",
       "1067                                      String theory   \n",
       "1068  The AdS/CFT correspondence is a relationship b...   \n",
       "1069  To explain the behavior of fundamental particl...   \n",
       "1070  T-duality reveals the existence of mirror symm...   \n",
       "\n",
       "                                                      B  \\\n",
       "771   Transcription occurs through a unique mechanis...   \n",
       "772   The viral fiber glycoproteins code for 40 prot...   \n",
       "773   The emission lines indicate that 3 Geminorum i...   \n",
       "774   They resemble the traps of the Venus fly trap ...   \n",
       "775   The microprocessor complex is responsible for ...   \n",
       "...                                                 ...   \n",
       "1066  The AdS/CFT correspondence provides a non-pert...   \n",
       "1067                                    Quantum gravity   \n",
       "1068  The AdS/CFT correspondence is the theory that ...   \n",
       "1069  To explain the behavior of large-scale structu...   \n",
       "1070  T-duality transforms compact dimensions of rad...   \n",
       "\n",
       "                                                      C  \\\n",
       "771   Reverse transcription is the method of transcr...   \n",
       "772   The viral fiber glycoproteins are responsible ...   \n",
       "773   The emission lines indicate that 3 Geminorum i...   \n",
       "774         They are covered by short and stout spines.   \n",
       "775   The microprocessor complex is involved in the ...   \n",
       "...                                                 ...   \n",
       "1066  The AdS/CFT correspondence represents a major ...   \n",
       "1067                             AdS/CFT correspondence   \n",
       "1068  The AdS/CFT correspondence is a dictionary tha...   \n",
       "1069  To describe the four fundamental forces acting...   \n",
       "1070  T-duality unifies gauge and gravity interactio...   \n",
       "\n",
       "                                                      D  \\\n",
       "771   DNA-templated transcription is the method of t...   \n",
       "772   The viral fiber glycoproteins mediate endocyto...   \n",
       "773   The emission lines indicate that 3 Geminorum i...   \n",
       "774   They are found on the central disc of the sea ...   \n",
       "775   The microprocessor complex is involved in the ...   \n",
       "...                                                 ...   \n",
       "1066  The AdS/CFT correspondence is a strong-weak du...   \n",
       "1067                                 General relativity   \n",
       "1068  The AdS/CFT correspondence is the equivalence ...   \n",
       "1069  To harmonize the theory of general relativity ...   \n",
       "1070  T-duality exchanges momentum modes for winding...   \n",
       "\n",
       "                                                      E answer_x  \\\n",
       "771   Transcription does not occur in the life cycle...        D   \n",
       "772   The viral fiber glycoproteins are responsible ...        D   \n",
       "773   The emission lines indicate that 3 Geminorum i...        A   \n",
       "774   They are a characteristic feature of the Gonia...        B   \n",
       "775   The microprocessor complex is responsible for ...        A   \n",
       "...                                                 ...      ...   \n",
       "1066  The AdS/CFT correspondence was first proposed ...        C   \n",
       "1067                                           M-theory        B   \n",
       "1068  The AdS/CFT correspondence is a mathematical c...        D   \n",
       "1069  To eliminate the infinities in quantum field t...        A   \n",
       "1070  T-duality explains the compactification of the...        A   \n",
       "\n",
       "                                                context  \\\n",
       "771   -There are three different replication systems...   \n",
       "772   -ASFV is a large (175–215 nm), icosahedral, do...   \n",
       "773   -Single antenna detections Radio observations ...   \n",
       "774   -Structure The three basic segments of the typ...   \n",
       "775   -The microprocessor complex is a protein compl...   \n",
       "...                                                 ...   \n",
       "1066  -In theoretical physics, anti-de Sitter/confor...   \n",
       "1067  -Quantum gravity and strings Current understan...   \n",
       "1068  -In theoretical physics, anti-de Sitter/confor...   \n",
       "1069  -Superstring theory is an attempt to explain a...   \n",
       "1070  -This transformation between the two 10-dimens...   \n",
       "\n",
       "                                          prompt_answer answer_y gpt4  \n",
       "771   What is the method of transcription in the lif...        D    D  \n",
       "772   What is the role of the viral fiber glycoprote...        D    D  \n",
       "773   What is the significance of the faint Hα emiss...        A    A  \n",
       "774   What is the significance of the pedicellariae ...        B    B  \n",
       "775   What is the role of the microprocessor complex...        A    A  \n",
       "...                                                 ...      ...  ...  \n",
       "1066  What is the significance of the anti-de Sitter...        C    C  \n",
       "1067  What is the branch of physics that seeks to de...        B    B  \n",
       "1068  What is the AdS/CFT correspondence according t...        D    D  \n",
       "1069  What is the purpose of superstring theory acco...        A    A  \n",
       "1070  What is the role of T-duality in string/M-theo...        A    B  \n",
       "\n",
       "[300 rows x 12 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5d2257-a2c6-40e6-b7a0-276f0aa202a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a27e4143-da98-4f33-92ed-31380be34fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data size: (200, 8)\n"
     ]
    }
   ],
   "source": [
    "df_valid = pd.read_csv('input_data/train_with_context2.csv')\n",
    "print('Validation data size:', df_valid.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "76014e6e-5dde-4dd9-9ce0-994d0a60ac01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: (46687, 8)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('input_data/all_12_with_context2.csv')\n",
    "df_train = df_train.drop(columns=\"source\")\n",
    "df_train = df_train.dropna(how='any', axis=0) # delete 4 choice question\n",
    "print('Train data size:', df_train.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cb99b4ef-88ef-4f46-91ca-1bf52b3fd9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>context</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In relation to Eunice Fay McKenzie's career, w...</td>\n",
       "      <td>Eunice Fay McKenzie (February 19, 1918 – April...</td>\n",
       "      <td>McKenzie showcased her singing talents in nume...</td>\n",
       "      <td>McKenzie is primarily remembered for her starr...</td>\n",
       "      <td>McKenzie gained recognition for her role as a ...</td>\n",
       "      <td>McKenzie's collaborations with director Blake ...</td>\n",
       "      <td>McKenzie's successful career in sound films co...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does Modified Newtonian Dynamics (MOND) im...</td>\n",
       "      <td>The presence of a clustered thick disk-like co...</td>\n",
       "      <td>MOND is a theory that increases the discrepanc...</td>\n",
       "      <td>MOND explains the missing baryonic mass in gal...</td>\n",
       "      <td>MOND is a theory that reduces the observed mis...</td>\n",
       "      <td>MOND is a theory that eliminates the observed ...</td>\n",
       "      <td>MOND's impact on the observed missing baryonic...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>Woody Hartman is a retired American soccer goa...</td>\n",
       "      <td>Ray Montgomerie is a former footballer who pla...</td>\n",
       "      <td>Ray Montgomerie is a former footballer who pla...</td>\n",
       "      <td>Ray Montgomerie is a former footballer who pla...</td>\n",
       "      <td>Ray Montgomerie is a former footballer who pla...</td>\n",
       "      <td>Ray Montgomerie is a former footballer who pla...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the significance of the Museum of the ...</td>\n",
       "      <td>The Museum of the Occupation of Latvia () is a...</td>\n",
       "      <td>The Museum of the Occupation of Latvia is a me...</td>\n",
       "      <td>The Museum of the Occupation of Latvia showcas...</td>\n",
       "      <td>The Museum of the Occupation of Latvia was est...</td>\n",
       "      <td>The Museum of the Occupation of Latvia primari...</td>\n",
       "      <td>The Museum of the Occupation of Latvia is a mu...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was the previous name of the Christian Sc...</td>\n",
       "      <td>It was named the Evangelical School for the De...</td>\n",
       "      <td>The Christian School for the Deaf (CSD)</td>\n",
       "      <td>The Christian School for the Blind (CSB)</td>\n",
       "      <td>The Evangelical School and Chapel for the Deaf...</td>\n",
       "      <td>The Evangelical School for the Deaf (ESD)</td>\n",
       "      <td>The Evangelical School for the Blind (ESB)</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  In relation to Eunice Fay McKenzie's career, w...   \n",
       "1  How does Modified Newtonian Dynamics (MOND) im...   \n",
       "2  Which of the following statements accurately d...   \n",
       "3  What is the significance of the Museum of the ...   \n",
       "4  What was the previous name of the Christian Sc...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Eunice Fay McKenzie (February 19, 1918 – April...   \n",
       "1  The presence of a clustered thick disk-like co...   \n",
       "2  Woody Hartman is a retired American soccer goa...   \n",
       "3  The Museum of the Occupation of Latvia () is a...   \n",
       "4  It was named the Evangelical School for the De...   \n",
       "\n",
       "                                                   A  \\\n",
       "0  McKenzie showcased her singing talents in nume...   \n",
       "1  MOND is a theory that increases the discrepanc...   \n",
       "2  Ray Montgomerie is a former footballer who pla...   \n",
       "3  The Museum of the Occupation of Latvia is a me...   \n",
       "4            The Christian School for the Deaf (CSD)   \n",
       "\n",
       "                                                   B  \\\n",
       "0  McKenzie is primarily remembered for her starr...   \n",
       "1  MOND explains the missing baryonic mass in gal...   \n",
       "2  Ray Montgomerie is a former footballer who pla...   \n",
       "3  The Museum of the Occupation of Latvia showcas...   \n",
       "4           The Christian School for the Blind (CSB)   \n",
       "\n",
       "                                                   C  \\\n",
       "0  McKenzie gained recognition for her role as a ...   \n",
       "1  MOND is a theory that reduces the observed mis...   \n",
       "2  Ray Montgomerie is a former footballer who pla...   \n",
       "3  The Museum of the Occupation of Latvia was est...   \n",
       "4  The Evangelical School and Chapel for the Deaf...   \n",
       "\n",
       "                                                   D  \\\n",
       "0  McKenzie's collaborations with director Blake ...   \n",
       "1  MOND is a theory that eliminates the observed ...   \n",
       "2  Ray Montgomerie is a former footballer who pla...   \n",
       "3  The Museum of the Occupation of Latvia primari...   \n",
       "4          The Evangelical School for the Deaf (ESD)   \n",
       "\n",
       "                                                   E answer  \n",
       "0  McKenzie's successful career in sound films co...      B  \n",
       "1  MOND's impact on the observed missing baryonic...      E  \n",
       "2  Ray Montgomerie is a former footballer who pla...      B  \n",
       "3  The Museum of the Occupation of Latvia is a mu...      C  \n",
       "4         The Evangelical School for the Blind (ESB)      D  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6e399bb-8026-4603-8767-61826adbf9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\n",
    "index_to_option = {v: k for k,v in option_to_index.items()}\n",
    "\n",
    "def preprocess(example):\n",
    "    first_sentence = [ \"[CLS] \" + example['context'] ] * 5\n",
    "    second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in 'ABCDE']\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentences, truncation='only_first', \n",
    "                                  max_length=MAX_INPUT, add_special_tokens=False)\n",
    "    tokenized_example['label'] = option_to_index[example['answer']]\n",
    "    \n",
    "    return tokenized_example\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    \n",
    "    def __call__(self, features):\n",
    "        label_name = 'label' if 'label' in features[0].keys() else 'labels'\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0]['input_ids'])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fc5bdbd1-5a45-44af-b4ff-c6bfbab2f18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "option_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b73c5033-8ad6-40d1-a14c-f8a83663c60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "265eeec5-56f9-4fa8-aa11-f4e54c688211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/workspace/.local/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "dataset_valid = Dataset.from_pandas(df_valid)\n",
    "dataset = Dataset.from_pandas(df_train)\n",
    "dataset = dataset.remove_columns([\"__index_level_0__\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "06c0d335-2b3a-4575-a028-892f5dd21b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d25b8751ef4679b515cc5d9009305d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4cf7a8edff4ae790843ea523380522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/46687 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset_valid = dataset_valid.map(preprocess, remove_columns=['prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer'])\n",
    "tokenized_dataset = dataset.map(preprocess, remove_columns=['prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0a40e782-bbe4-464f-af04-6c3b761ac39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "733e0e20-a37c-47d4-89eb-eff4aa5b9428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "998c037b-98f3-465f-bab6-df46156fb8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cntx = df_train.head(1)['context'].values[0]\n",
    "pmpt = df_train.head(1)['prompt'].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "caa17e45-9f5c-4cc7-a9a5-d68efdf262d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In relation to Eunice Fay McKenzie's career, which statement accurately reflects her most notable work?\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b88622e-f452-4f89-ab7e-3b5229332963",
   "metadata": {},
   "outputs": [],
   "source": [
    "check =  [ \"[CLS] \" + cntx ] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b31be14-7e8a-4d34-984e-39c3870a300d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_sentence = [ \"[CLS] \" + cntx ] * 5\n",
    "second_sentences = [\" #### \" + pmpt + \" [SEP] \" + df_train.head(1)[option].values[0] + \" [SEP]\" for option in 'ABCDE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2975039c-d5d8-4f0e-b464-b9044f0420f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" #### In relation to Eunice Fay McKenzie's career, which statement accurately reflects her most notable work? [SEP] McKenzie showcased her singing talents in numerous musical productions, garnering critical acclaim. [SEP]\",\n",
       " \" #### In relation to Eunice Fay McKenzie's career, which statement accurately reflects her most notable work? [SEP] McKenzie is primarily remembered for her starring roles opposite Gene Autry in popular Western films of the 1940s. [SEP]\",\n",
       " \" #### In relation to Eunice Fay McKenzie's career, which statement accurately reflects her most notable work? [SEP] McKenzie gained recognition for her role as a child actress in a series of iconic silent films. [SEP]\",\n",
       " \" #### In relation to Eunice Fay McKenzie's career, which statement accurately reflects her most notable work? [SEP] McKenzie's collaborations with director Blake Edwards were instrumental in her rise to fame. [SEP]\",\n",
       " \" #### In relation to Eunice Fay McKenzie's career, which statement accurately reflects her most notable work? [SEP] McKenzie's successful career in sound films continued into adulthood, becoming known for her versatile acting abilities. [SEP]\"]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f02e979e-6eb5-44c1-8d26-41d49ed6e044",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_example = tokenizer(first_sentence, second_sentences, truncation='only_first', \n",
    "                                  max_length=MAX_INPUT, add_special_tokens=False)\n",
    "# tokenized_example['label'] = option_to_index[example['answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c90bb800-6f50-4a29-a441-d5b6a3fa3f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Eunice Fay McKenzie (February 19, 1918 – April 16, 2019) was an American actress and singer. She also entertained the troops with her former screen partner, Gene Autry. ===Later career=== After World War II, McKenzie retired from films to raise her two children. She was briefly billed as Fay Shannon. ==Biography== ===Early life and silent film=== McKenzie was born on February 19, 1918, in Hollywood, California, to show business parents, film actor Eva (née Heazlitt) and Irish American actor/director Robert McKenzie.Mike Fitzgerald, \"An Interview with... She starred in silent films as a child, and then sound films as an adult, but perhaps she is best known for her leading roles opposite Gene Autry in the early 1940s in five horse opera features. Fay\\'s sister Ida Mae McKenzie, cousin Ella McKenzie, and brother-in-law Billy Gilbert, were also actors. McKenzie sang duets with Autry in each of these films. Ida Mae also played the character of Sarah Lincoln in The Dramatic Life of Abraham Lincoln, in the part of the film where she had become a teenager. ===Schooling=== In the mid-1920s, McKenzie took a ten-year break from acting in order to focus on her education. Her father had a stock company called the McKenzie Merry #### In relation to Eunice Fay McKenzie\\'s career, which statement accurately reflects her most notable work?[SEP] McKenzie showcased her singing talents in numerous musical productions, garnering critical acclaim.[SEP]'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_example['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf8ac92b-6178-4287-b7ad-158b37e614a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Eunice Fay McKenzie (February 19, 1918 – April 16, 2019) was an American actress and singer. She also entertained the troops with her former screen partner, Gene Autry. ===Later career=== After World War II, McKenzie retired from films to raise her two children. She was briefly billed as Fay Shannon. ==Biography== ===Early life and silent film=== McKenzie was born on February 19, 1918, in Hollywood, California, to show business parents, film actor Eva (née Heazlitt) and Irish American actor/director Robert McKenzie.Mike Fitzgerald, \"An Interview with... She starred in silent films as a child, and then sound films as an adult, but perhaps she is best known for her leading roles opposite Gene Autry in the early 1940s in five horse opera features. Fay\\'s sister Ida Mae McKenzie, cousin Ella McKenzie, and brother-in-law Billy Gilbert, were also actors. McKenzie sang duets with Autry in each of these films. Ida Mae also played the character of Sarah Lincoln in The Dramatic Life of Abraham Lincoln, in the part of the film where she had become a teenager. ===Schooling=== In the mid-1920s, McKenzie took a ten-year break from acting in order to focus on her education. Her father had a #### In relation to Eunice Fay McKenzie\\'s career, which statement accurately reflects her most notable work?[SEP] McKenzie is primarily remembered for her starring roles opposite Gene Autry in popular Western films of the 1940s.[SEP]'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenized_example['input_ids'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38637471-4f03-41a0-a74a-eb33220c96a9",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fbff5603-e54f-4554-8e7d-84b2556dc065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_model_tokeinzer(path, model_type):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(path, use_fast=False)\n",
    "    if model_type == 'causal':\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            path,\n",
    "            torch_dtype=torch.float32,\n",
    "            trust_remote_code=True,\n",
    "            # low_cpu_mem_usage=True,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "    elif model_type == 'seq':\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(path,num_labels=1)\n",
    "    elif model_type == 'multic':\n",
    "        model = AutoModelForMultipleChoice.from_pretrained(path)\n",
    "    \n",
    "    return tokenizer, model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5ad51362-6e66-40fa-b3e5-9a88670bbc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = MODEL\n",
    "model_type =  'multic' # ['seq','causal','multic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d57d778f-9263-465e-8220-5daa02375e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model from directory: 'models/microsoft/deberta-v3-large' \n"
     ]
    }
   ],
   "source": [
    "directory = f\"models/{model_name}\"\n",
    "\n",
    "if os.path.exists(directory):\n",
    "    print(f\"Loading Model from directory: '{directory}' \")\n",
    "    tokenizer, model = _get_model_tokeinzer(directory,model_type)\n",
    "else:\n",
    "    print(f\"Downloading Model from huggingface: '{model_name}' \")\n",
    "    tokenizer, model = _get_model_tokeinzer(model_name,model_type)\n",
    "    # Save the model weights to disk\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"Saving the Model from directory: '{directory}' \")\n",
    "    model.save_pretrained(directory)\n",
    "    tokenizer.save_pretrained(directory)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "99bff051-2102-4a6e-ac62-41c66dbd65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_at_3(predictions, labels):\n",
    "    map_sum = 0\n",
    "    pred = np.argsort(-1*np.array(predictions),axis=1)[:,:3]\n",
    "    for x,y in zip(pred,labels):\n",
    "        z = [1/i if y==j else 0 for i,j in zip([1,2,3],x)]\n",
    "        map_sum += np.sum(z)\n",
    "    return map_sum / len(predictions)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions = p.predictions.tolist()\n",
    "    labels = p.label_ids.tolist()\n",
    "    return {\"map@3\": map_at_3(predictions, labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "01cc4f4d-972a-49bf-b37d-0c237ad15b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/workspace/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    warmup_ratio=0.1, \n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    report_to='none',\n",
    "    output_dir = f\"output/{model_name}-{VER}\",\n",
    "    overwrite_output_dir=True,\n",
    "    fp16=False,\n",
    "    gradient_accumulation_steps=8,\n",
    "    logging_steps=25,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=25,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=25,\n",
    "    load_best_model_at_end=False,\n",
    "    metric_for_best_model='map@3',\n",
    "    lr_scheduler_type='cosine',\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40b0951-1d52-4ed2-a477-ff15690d13a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset_valid,\n",
    "    compute_metrics = compute_metrics,\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(f'model_v{VER}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb2568f-2194-4ff6-b904-0cf8930c93f3",
   "metadata": {},
   "source": [
    "# Load ~Saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85f39f9f-a9cd-46ba-843e-c650f40bbe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if USE_PEFT:\n",
    "#     model = AutoModelForMultipleChoice.from_pretrained(MODEL)\n",
    "#     model = get_peft_model(model, peft_config)\n",
    "#     checkpoint = torch.load(f'model_v{VER}/pytorch_model.bin')\n",
    "#     model.load_state_dict(checkpoint)\n",
    "# else:\n",
    "model = AutoModelForMultipleChoice.from_pretrained(f'output/{model_name}-{VER}-saved',torch_dtype=torch.float16)\n",
    "trainer = Trainer(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25cadc58-93dc-4727-ac62-eace95dab2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(f'output/{model_name}-{VER}-saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "899815da-73ea-4f4b-a1b9-e43b596fc1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_INPUT = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08d859f7-fc70-4fc4-94cf-b41b288618f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\n",
    "index_to_option = {v: k for k,v in option_to_index.items()}\n",
    "\n",
    "\n",
    "def preprocess(example):\n",
    "    first_sentence = \"[CLS] \" + example['context']\n",
    "    second_sentences = [\" #### \" + example['prompt'] + \" [SEP] \" + example[option] + \" [SEP]\" for option in 'ABCDE']\n",
    "    \n",
    "    tokenized_examples = tokenizer([first_sentence] * 5, second_sentences, truncation=True, padding='max_length', max_length=MAX_INPUT, add_special_tokens=False, return_tensors='pt')\n",
    "    \n",
    "    tokenized_examples['label'] = option_to_index[example['answer']]\n",
    "    \n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bba5236-8fa2-4686-a54e-b25b8491e82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd89e36fbec04f65a277d7a3f8fed0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv('input_data/train_with_context2.csv')\n",
    "tokenized_test_dataset = Dataset.from_pandas(test_df).map(\n",
    "        preprocess, remove_columns=['prompt', 'context', 'A', 'B', 'C', 'D', 'E'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "557d3522-602f-486c-9806-be8429096027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM,AutoModelForMultipleChoice, AutoTokenizer, AutoModel,BitsAndBytesConfig\n",
    "from accelerate import init_empty_weights\n",
    "from accelerate.utils.modeling import set_module_tensor_to_device\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "from peft import LoraConfig, get_peft_model \n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918a9dc1-2019-4b7f-b7cc-361bb9fc0dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/mistral_c/mistralai/Mistral-7B-v0.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b09dcf-1bb3-46a3-b799-e4d9f9e01efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62eb11271be4011a933a1f7345368f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "#     load_in_8bit=True,\n",
    "    trust_remote_code=True,\n",
    "#     low_cpu_mem_usage=True,\n",
    "    device_map=\"auto\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "116ebe42-9b2e-4a8b-a155-b60b24d93f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    # layers_to_transform = [25,26,27,28,29,30,31,32],\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\",\"up_proj\", \"down_proj\",\"lm_head\"],\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a808d13-95b9-4ba8-bed9-4ca620ca4ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b57a777c-8ca1-418f-a0af-83d5084a54fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a9cebd3-d450-4bdd-a3ef-883a1824a140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_linear_layers(model):\n",
    "    \"\"\" find linear layers in given transformer model \"\"\"\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        # 4 bits for qlora\n",
    "        # if isinstance(module, nn.Linear): \n",
    "        print(module)\n",
    "        names = name.split('.')\n",
    "        lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "    if 'lm_head' in lora_module_names:\n",
    "        lora_module_names.remove('lm_head')\n",
    "    print(f\"LoRA module names: {list(lora_module_names)}\")\n",
    "    return list(lora_module_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c359cf00-01ae-43a8-9c21-555ea5bb972e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e16c827a-dc6f-43e2-b4b2-9b70099fae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c6e7203-6f99-429f-8c2b-967588d20a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 170082304 || all params: 7411814400 || trainable%: 2.2947458587198297\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_model = get_peft_model(model, lora_config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f51caec2-f53e-45dd-b4c4-381fce106148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c342ad5a-8eff-44f1-bfa1-f75ddb8be364",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor([3, 0, 3, 3, 0, 4, 3, 0, 3, 4, 4, 3])\n",
    "y_preds = torch.tensor([\n",
    "    [ 0.0809,  0.1396, -0.0039,  0.1592,  0.0755],\n",
    "    [ 0.0881,  0.1466, -0.0024,  0.1619,  0.0827],\n",
    "    [ 0.0910,  0.1463,  0.0056,  0.1694,  0.0862],\n",
    "    [ 0.0878,  0.1381, -0.0026,  0.1658,  0.0776],\n",
    "    [ 0.0795,  0.1336, -0.0080,  0.1588,  0.0768],\n",
    "    [ 0.0787,  0.1359, -0.0029,  0.1639,  0.0768],\n",
    "    [ 0.0841,  0.1335, -0.0039,  0.1603,  0.0808],\n",
    "    [ 0.0921,  0.1506,  0.0006,  0.1663,  0.0889],\n",
    "    [ 0.0819,  0.1423, -0.0025,  0.1623,  0.0814],\n",
    "    [ 0.0825,  0.1419, -0.0056,  0.1591,  0.0781],\n",
    "    [ 0.0906,  0.1427, -0.0031,  0.1647,  0.0822],\n",
    "    [ 0.0837,  0.1398, -0.0032,  0.1606,  0.0798]\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a068535b-c048-4085-aba5-8114fbf1955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listnet_loss(y_pred, y_true):\n",
    "    # Convert the ground truth to one-hot encoding\n",
    "    y_true_onehot = F.one_hot(y_true, num_classes=y_pred.size(1)).float()\n",
    "\n",
    "    # Ensure the predictions are in the same order as y_true.\n",
    "    _, indices = torch.sort(y_true_onehot, descending=True, dim=1)\n",
    "    y_pred = torch.gather(y_pred, 1, indices)\n",
    "\n",
    "    # Compute softmax over raw scores\n",
    "    y_pred_softmax = F.softmax(y_pred, dim=1)\n",
    "    \n",
    "    # Compute cross-entropy\n",
    "    loss = -torch.mean(torch.sum(y_true_onehot * torch.log(y_pred_softmax), dim=1))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7664b273-c450-48fe-b921-9322bdf12788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6430)\n"
     ]
    }
   ],
   "source": [
    "l_loss = listnet_loss(y_preds, labels)\n",
    "print(l_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3bcfd27c-775a-46f5-abbc-0ab30e88bd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the cross-entropy loss for each sample\n",
    "losses = F.cross_entropy(y_preds, labels, reduction='none')\n",
    "\n",
    "# Multiply the losses by the corresponding weights\n",
    "weighted_losses = losses * weight_matrix[torch.arange(weight_matrix.shape[0]), labels]\n",
    "\n",
    "# Compute the average weighted loss\n",
    "avg_weighted_loss = torch.mean(weighted_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "927991d5-27c7-47b7-9bd6-3f13df2ebd16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c584c33-02ff-4655-b228-2b92858d4ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fct = nn.CrossEntropyLoss()\n",
    "loss =  loss_fct(y_preds, labels.view(-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b49fb25-15f9-48fe-942e-6d0a99b16b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.5815), tensor(1.5815))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_weighted_loss, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2064bd4a-c679-40bf-8377-6012cced6996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27b91b4a-0ff4-4dda-88ce-c69cf5637cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_id = \"output/baseline_mistral_c\"\n",
    "config = PeftConfig.from_pretrained(peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d56dfca4-cbc0-4e7d-aa95-a7c2ba9327c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model = PeftModel.from_pretrained(model,peft_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e02211-3e45-4826-9e3f-137bc238b97b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_predictions = trainer.predict(tokenized_test_dataset).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9f19d5-1dee-4b69-ad55-f6866fc8d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = trainer.predict(tokenized_test_dataset).predictions\n",
    "predictions_as_ids = np.argsort(-test_predictions, 1)\n",
    "predictions_as_answer_letters = np.array(list('ABCDE'))[predictions_as_ids]\n",
    "predictions_as_string = test_df['prediction'] = [\n",
    "    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7163fd5e-c790-484f-8578-3cbc772f9bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data 40k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a774196a-a58c-4061-89c0-bdea2b81ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_openbook = pd.read_csv('input_data/validation_data/40k_dataset/MMLU_17k_with_context2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a0522777-1aee-4696-a7fc-3b041197ba7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>context</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>answer</th>\n",
       "      <th>is_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In which of the following cases is a convictio...</td>\n",
       "      <td>Aggravated Robbery 4-15 years in prison. ===In...</td>\n",
       "      <td>Johnson forced his way into a woman's home, bo...</td>\n",
       "      <td>A confederate of Brown pushed a man in order t...</td>\n",
       "      <td>Having induced a woman to enter his hotel room...</td>\n",
       "      <td>Hayes unbuttoned the vest of a man too drunk t...</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In which of the following situations is Defend...</td>\n",
       "      <td>The prosecutor may decide not to prosecute a c...</td>\n",
       "      <td>Police arrested Thief and recovered goods he h...</td>\n",
       "      <td>Defendant misrepresented his identity to secur...</td>\n",
       "      <td>Believing that state law made it a crime to pu...</td>\n",
       "      <td>Defendant, intending to kill Selma, shot at Se...</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Potts sued Dobbs on a product liability claim....</td>\n",
       "      <td>Bazley v Curry, [1999] 2 SCR 534 is a Supreme ...</td>\n",
       "      <td>\"Isn't it a fact that you are Potts' close fri...</td>\n",
       "      <td>\"Isn't it true that you are known in the commu...</td>\n",
       "      <td>\"Didn't you fail to report some income on your...</td>\n",
       "      <td>\"Weren't you convicted, seven years ago in thi...</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In which of the following situations is Defend...</td>\n",
       "      <td>It is considered the most serious form of homi...</td>\n",
       "      <td>Angered because his neighbor is having a noisy...</td>\n",
       "      <td>During an argument, Harry slaps Defendant. Ang...</td>\n",
       "      <td>Defendant drives his car through a red light a...</td>\n",
       "      <td>Using his fist, Defendant punches Walter in th...</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Redirect examination of a witness must be perm...</td>\n",
       "      <td>Redirect examination, performed by the attorne...</td>\n",
       "      <td>To reply to any matter raised in crossexaminat...</td>\n",
       "      <td>Only to reply to significant new matter raised...</td>\n",
       "      <td>Only to reiterate the essential elements of th...</td>\n",
       "      <td>Only to supply significant information inadver...</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "2  In which of the following cases is a convictio...   \n",
       "4  In which of the following situations is Defend...   \n",
       "5  Potts sued Dobbs on a product liability claim....   \n",
       "6  In which of the following situations is Defend...   \n",
       "8  Redirect examination of a witness must be perm...   \n",
       "\n",
       "                                             context  \\\n",
       "2  Aggravated Robbery 4-15 years in prison. ===In...   \n",
       "4  The prosecutor may decide not to prosecute a c...   \n",
       "5  Bazley v Curry, [1999] 2 SCR 534 is a Supreme ...   \n",
       "6  It is considered the most serious form of homi...   \n",
       "8  Redirect examination, performed by the attorne...   \n",
       "\n",
       "                                                   A  \\\n",
       "2  Johnson forced his way into a woman's home, bo...   \n",
       "4  Police arrested Thief and recovered goods he h...   \n",
       "5  \"Isn't it a fact that you are Potts' close fri...   \n",
       "6  Angered because his neighbor is having a noisy...   \n",
       "8  To reply to any matter raised in crossexaminat...   \n",
       "\n",
       "                                                   B  \\\n",
       "2  A confederate of Brown pushed a man in order t...   \n",
       "4  Defendant misrepresented his identity to secur...   \n",
       "5  \"Isn't it true that you are known in the commu...   \n",
       "6  During an argument, Harry slaps Defendant. Ang...   \n",
       "8  Only to reply to significant new matter raised...   \n",
       "\n",
       "                                                   C  \\\n",
       "2  Having induced a woman to enter his hotel room...   \n",
       "4  Believing that state law made it a crime to pu...   \n",
       "5  \"Didn't you fail to report some income on your...   \n",
       "6  Defendant drives his car through a red light a...   \n",
       "8  Only to reiterate the essential elements of th...   \n",
       "\n",
       "                                                   D answer  is_question  \n",
       "2  Hayes unbuttoned the vest of a man too drunk t...      D         True  \n",
       "4  Defendant, intending to kill Selma, shot at Se...      C         True  \n",
       "5  \"Weren't you convicted, seven years ago in thi...      B         True  \n",
       "6  Using his fist, Defendant punches Walter in th...      A         True  \n",
       "8  Only to supply significant information inadver...      B         True  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_openbook[df_openbook.is_question].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7df6eb69-d6a4-4601-9d14-7ba4065b2539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Which occurs as a result of Earth's tilt on its rotating axis?\""
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_openbook[df_openbook.is_question].iloc[20]['prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e93ea2f1-5192-4220-a7c8-9466cbc89498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Johnson forced his way into a woman's home, bound her, and compelled her to tell him that her jewelry was in an adjoining room. Johnson went to the room, took the jewelry, and fled. \"]\n",
      "['A confederate of Brown pushed a man in order to cause him to lose his balance and drop his briefcase. Brown picked up the briefcase and ran off with it.']\n",
      "['Having induced a woman to enter his hotel room, Ritter forced her to telephone her maid to tell the maid to bring certain jewelry to the hotel. Ritter locked the woman in the bathroom while he accepted the jewelry from the maid when she arrived. ']\n",
      "['Hayes unbuttoned the vest of a man too drunk to notice and removed his wallet. A minute later, the victim missed his wallet and accused Hayes of taking it. Hayes pretended to be insulted, slapped the victim, and went off with the wallet.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(df_openbook[df_openbook.is_question].head(1)[letter].values) for letter in ['A','B','C','D']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c6bddb6-8ea8-435a-acd4-6908afdbbec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e82c44-153a-4b92-8706-0a5b341a3dc1",
   "metadata": {},
   "source": [
    "# validation score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23c3b0b8-789c-43a8-be38-02b190713acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a3092d75-ffee-4c2f-af01-c6236426cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/philippsinger/h2ogpt-perplexity-ranking\n",
    "import numpy as np\n",
    "def precision_at_k(r, k):\n",
    "    \"\"\"Precision at k\"\"\"\n",
    "    assert k <= len(r)\n",
    "    assert k != 0\n",
    "    return sum(int(x) for x in r[:k]) / k\n",
    "\n",
    "def MAP_at_3(predictions, true_items):\n",
    "    \"\"\"Score is mean average precision at 3\"\"\"\n",
    "    U = len(predictions)\n",
    "    map_at_3 = 0.0\n",
    "    for u in range(U):\n",
    "        user_preds = predictions[u].split()\n",
    "        user_true = true_items[u]\n",
    "        user_results = [1 if item == user_true else 0 for item in user_preds]\n",
    "        for k in range(min(len(user_preds), 3)):\n",
    "            map_at_3 += precision_at_k(user_results, k+1) * user_results[k]\n",
    "    return map_at_3 / U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "072052c5-a734-4af8-a10e-1aaf19dbb564",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_actual = pd.read_csv('input_data/validation_data/master_validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3a9d1b72-e17f-427f-b9cc-de25fa35c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deberta_context_1 = pd.read_csv('base/validation_data_fold1_768.csv')\n",
    "df_deberta_context_2 = pd.read_csv('base/validation_data_fold2_768.csv')\n",
    "df_deberta_context_0 = pd.read_csv('base/validation_data_fold0_768.csv')\n",
    "df_deberta_context_all = pd.read_csv('base/validation_data_fold0_80k.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3ad786c7-d80e-472e-95f7-3c675a09349f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_deberta_context_1['deberta_choice_1'] = df_deberta_context_1['prediction'].str[0]\n",
    "# df_deberta_context_1['deberta_choice_2'] = df_deberta_context_1['prediction'].str[2]\n",
    "# df_deberta_context_1['deberta_choice_3'] = df_deberta_context_1['prediction'].str[4]\n",
    "\n",
    "dfs = [df_deberta_context_all,df_deberta_context_0,df_deberta_context_1,df_deberta_context_2]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6f39db3d-4d1a-4c30-b042-b8d043c10bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract probability by index\n",
    "def extract_prob_by_index(row_str, index):\n",
    "    try:\n",
    "        # Convert the string back to a list\n",
    "        row = literal_eval(row_str)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None\n",
    "    \n",
    "    if index < len(row):\n",
    "        return row[index]\n",
    "    return None\n",
    "\n",
    "def calc_choice_accuracy(df):\n",
    "    top1_deberta = accuracy_score(df['answer'].values,df['deberta_choice_1'].values )\n",
    "    top2_deberta = accuracy_score(df['answer'].values,df['deberta_choice_2'].values )\n",
    "    top3_deberta = accuracy_score(df['answer'].values,df['deberta_choice_3'].values )\n",
    "    print(f\"TOP 1 :{round(top1_deberta,2)} , TOP 2 :{round(top2_deberta,2)}, TOP 3 :{round(top3_deberta,2)}\")\n",
    "\n",
    "# Create new columns\n",
    "labels = ['A', 'B', 'C', 'D', 'E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "27e47873-860d-461d-8c8c-7e3613d5a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, df in enumerate(dfs):\n",
    "    df['deberta_choice_1'] = df['prediction'].str[0]\n",
    "    df['deberta_choice_2'] = df['prediction'].str[2]\n",
    "    df['deberta_choice_3'] = df['prediction'].str[4]\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        df[f'{label}_prob'] = df['probabilities'].apply(lambda row: extract_prob_by_index(row, i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3b16fcdd-1a2f-451e-a07f-5a661dc4f8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAP@3 = 0.886876640419948\n"
     ]
    }
   ],
   "source": [
    "m = MAP_at_3(df_deberta_context_all.prediction.values, df_deberta_context_all.answer.values)\n",
    "print( 'CV MAP@3 =',m )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b7d64c8f-182e-4d35-a643-f5b71d0321df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAP@3 = 0.8759842519685046\n"
     ]
    }
   ],
   "source": [
    "m = MAP_at_3(df_deberta_context_0.prediction.values, df_deberta_context_0.answer.values)\n",
    "print( 'CV MAP@3 =',m )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "aa1a1fc8-a4fc-49b5-918a-2234f8504830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAP@3 = 0.8641732283464576\n"
     ]
    }
   ],
   "source": [
    "m = MAP_at_3(df_deberta_context_1.prediction.values, df_deberta_context_1.answer.values)\n",
    "print( 'CV MAP@3 =',m )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2f4c7a7e-df83-4de6-b2df-6f0fb034beb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAP@3 = 0.8696850393700798\n"
     ]
    }
   ],
   "source": [
    "m = MAP_at_3(df_deberta_context_2.prediction.values, df_deberta_context_2.answer.values)\n",
    "print( 'CV MAP@3 =',m )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "dcd0fed9-8772-4615-b9d0-15e7ec43bbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 1 :0.82 , TOP 2 :0.1, TOP 3 :0.04\n",
      "TOP 1 :0.81 , TOP 2 :0.11, TOP 3 :0.04\n",
      "TOP 1 :0.79 , TOP 2 :0.11, TOP 3 :0.06\n",
      "TOP 1 :0.8 , TOP 2 :0.11, TOP 3 :0.05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_choice_accuracy(df_deberta_context_all) , calc_choice_accuracy(df_deberta_context_0) , calc_choice_accuracy(df_deberta_context_1), calc_choice_accuracy(df_deberta_context_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fa24e052-c263-4524-b132-fc22b8ddbbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that the 'id', 'prompt', 'context', and 'answer' columns are consistent across the three dataframes:\n",
    "df_weighted = df_deberta_context_0[['id', 'prompt', 'context', 'answer']].copy()\n",
    "\n",
    "columns = ['A_prob', 'B_prob', 'C_prob', 'D_prob', 'E_prob']\n",
    "# weight = 1/3\n",
    "\n",
    "for col in columns:\n",
    "    df_weighted[col.replace('_prob', '_weighted_prob')] = (\n",
    "        0.25 * df_deberta_context_0[col] + \n",
    "        0.15 * df_deberta_context_1[col] + \n",
    "        0.20 * df_deberta_context_2[col] +\n",
    "        0.40 * df_deberta_context_all[col]   \n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e1e3d-64fc-4d45-935d-2ee303534993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb785d6-f027-49c2-850d-6d147a409a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5031e0-7ae5-41cf-b2fa-0300d8ef72eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c2ff0fdb-a1e7-465c-83b7-9b912665b857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'prompt', 'context', 'answer', 'A_weighted_prob',\n",
       "       'B_weighted_prob', 'C_weighted_prob', 'D_weighted_prob',\n",
       "       'E_weighted_prob'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weighted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6fff66cb-a6c5-4099-9b72-93319ff193df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_as_ids = np.argsort(-df_weighted[['A_weighted_prob',\n",
    "       'B_weighted_prob', 'C_weighted_prob', 'D_weighted_prob',\n",
    "       'E_weighted_prob']].values, 1)\n",
    "\n",
    "predictions_as_answer_letters = np.array(list('ABCDE'))[predictions_as_ids]\n",
    "\n",
    "predictions_as_string = df_weighted['prediction'] = [\n",
    "    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a38517aa-f23b-4320-b648-ea4b64192acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## mean pred\n",
    "dfs = [df_weighted]\n",
    "for idx, df in enumerate(dfs):\n",
    "    df['deberta_choice_1'] = df['prediction'].str[0]\n",
    "    df['deberta_choice_2'] = df['prediction'].str[2]\n",
    "    df['deberta_choice_3'] = df['prediction'].str[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f7c8d42a-9e5e-41ea-8052-fbb4718f3d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 1 :0.84 , TOP 2 :0.1, TOP 3 :0.04\n"
     ]
    }
   ],
   "source": [
    "calc_choice_accuracy(df_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4e795050-fdcc-44ce-b126-35396b70a182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1270, 13)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9f96f420-1199-4949-b8e6-f04da76fa1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAP@3 = 0.8980314960629928\n"
     ]
    }
   ],
   "source": [
    "m = MAP_at_3(df_weighted.prediction.values, df_weighted.answer.values)\n",
    "print( 'CV MAP@3 =',m )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "50808990-dc60-44da-ba27-83c8d3bb402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lora = pd.read_csv('base/validation_data_mistral_LORA_predicted_newarticle1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e20b645-6e22-42a1-9d35-9c636f7d3983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAP@3 = 0.8914698162729665\n"
     ]
    }
   ],
   "source": [
    "m = MAP_at_3(df_lora.prediction.values, df_lora.answer.values)\n",
    "print( 'CV MAP@3 =',m )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "63bea173-5f22-4f2e-bf79-0610c164de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lora['lora_choice_1'] = df_lora['prediction'].str[0]\n",
    "df_lora['lora_choice_2'] = df_lora['prediction'].str[2]\n",
    "df_lora['lora_choice_3'] = df_lora['prediction'].str[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "895df860-a843-472d-9c79-c679f1c73d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 1 :0.82 , TOP 2 :0.11, TOP 3 :0.04\n"
     ]
    }
   ],
   "source": [
    "top1_lora = accuracy_score(df_lora['answer'].values,df_lora['lora_choice_1'].values )\n",
    "top2_lora = accuracy_score(df_lora['answer'].values,df_lora['lora_choice_2'].values )\n",
    "top3_lora = accuracy_score(df_lora['answer'].values,df_lora['lora_choice_3'].values )\n",
    "print(f\"TOP 1 :{round(top1_lora,2)} , TOP 2 :{round(top2_lora,2)}, TOP 3 :{round(top3_lora,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f5ce0c85-e63b-4f11-bec0-18d82768db3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to extract probability by label\n",
    "def extract_prob(row_str, label):\n",
    "    try:\n",
    "        # Convert the string back to a list of tuples\n",
    "        row = literal_eval(row_str.replace(\"array(\", \"\").replace(\", dtype=float32)\", \"\"))\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None\n",
    "    \n",
    "    for prob, lbl in row:\n",
    "        if lbl == label:\n",
    "            return float(prob)\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "# Create new columns\n",
    "for label in ['A', 'B', 'C', 'D', 'E']:\n",
    "    df_lora[f'{label}_prob'] = df_lora['logits'].apply(lambda row: extract_prob(row, label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5d88ac14-eca0-4c1d-82bc-9e45d70fabbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1270, 20), (1270, 13))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lora.shape, df_weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1ee60f0a-f3ee-47ce-bac3-14a1938332bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weighted_add_lora = df_weighted.merge(df_lora[['id','lora_choice_1','lora_choice_2','lora_choice_3']], on=['id'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "37289bee-bc33-4553-94fc-6ffd37ab8db4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Fixing the issue in the implementation to avoid duplication in the prediction string\n",
    "for index, row in df_weighted_add_lora.iterrows():\n",
    "    prediction_values = []\n",
    "    added_choices = set()\n",
    "    \n",
    "    if row['deberta_choice_1'] not in added_choices:\n",
    "        prediction_values.append(row['deberta_choice_1'])\n",
    "        added_choices.add(row['deberta_choice_1'])\n",
    "        \n",
    "    if row['lora_choice_1'] not in added_choices and len(prediction_values) < 3:\n",
    "        prediction_values.append(row['lora_choice_1'])\n",
    "        added_choices.add(row['lora_choice_1'])\n",
    "        \n",
    "    if row['lora_choice_2'] not in added_choices and len(prediction_values) < 3:\n",
    "        prediction_values.append(row['lora_choice_2'])\n",
    "        added_choices.add(row['lora_choice_2'])\n",
    "    \n",
    "    if row['deberta_choice_2'] not in added_choices and len(prediction_values) < 3:\n",
    "        prediction_values.append(row['deberta_choice_2'])\n",
    "        added_choices.add(row['deberta_choice_2'])\n",
    "\n",
    "    if row['deberta_choice_3'] not in added_choices and len(prediction_values) < 3:\n",
    "        prediction_values.append(row['deberta_choice_3'])\n",
    "        added_choices.add(row['deberta_choice_3'])\n",
    "    \n",
    "    # Join the top 3 non-unique values to form the prediction string\n",
    "    df_weighted_add_lora.at[index, 'deberta_lora'] = ' '.join(prediction_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5f521432-9eeb-4261-a526-1bb2f2361852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAP@3 = 0.8972440944881896\n"
     ]
    }
   ],
   "source": [
    "m = MAP_at_3(df_weighted_add_lora.deberta_lora.values, df_weighted_add_lora.answer.values)\n",
    "print( 'CV MAP@3 =',m )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "33c94f81-a068-4a80-85e6-06e81dd8289b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 1 :0.84 , TOP 2 :0.1, TOP 3 :0.04\n"
     ]
    }
   ],
   "source": [
    "calc_choice_accuracy(df_weighted_add_lora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aa9f0c29-5eb4-4e86-97b3-4545ad89a96c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>instruction</th>\n",
       "      <th>prediction</th>\n",
       "      <th>logits</th>\n",
       "      <th>lora_choice_1</th>\n",
       "      <th>lora_choice_2</th>\n",
       "      <th>lora_choice_3</th>\n",
       "      <th>A_prob</th>\n",
       "      <th>B_prob</th>\n",
       "      <th>C_prob</th>\n",
       "      <th>D_prob</th>\n",
       "      <th>E_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What does a diffusion-limited enzyme represent...</td>\n",
       "      <td>An intrinsic, physical constraint</td>\n",
       "      <td>A maximum peak height in the fitness landscape</td>\n",
       "      <td>An evolutionary limitation</td>\n",
       "      <td>A chemical limitation</td>\n",
       "      <td>A diffusion limitation</td>\n",
       "      <td>B</td>\n",
       "      <td>-A diffusion-limited enzyme catalyses a reacti...</td>\n",
       "      <td>What does a diffusion-limited enzyme represent...</td>\n",
       "      <td>A B C</td>\n",
       "      <td>[(array(0.53893685, dtype=float32), 'A'), (arr...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>0.538937</td>\n",
       "      <td>0.453830</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.002102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What are known clusters of neurons in the medu...</td>\n",
       "      <td>baroreceptors</td>\n",
       "      <td>angioreceptors</td>\n",
       "      <td>the cardiomotor mechanism</td>\n",
       "      <td>the cardiovascular center</td>\n",
       "      <td>angioreceptors</td>\n",
       "      <td>D</td>\n",
       "      <td>-Regulation of blood pressure The endogenous, ...</td>\n",
       "      <td>What are known clusters of neurons in the medu...</td>\n",
       "      <td>D C A</td>\n",
       "      <td>[(array(0.03887285, dtype=float32), 'A'), (arr...</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>0.038873</td>\n",
       "      <td>0.014987</td>\n",
       "      <td>0.095463</td>\n",
       "      <td>0.837657</td>\n",
       "      <td>0.013021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>How was sulfur produced in the United States i...</td>\n",
       "      <td>Sulfur production in the United States was pri...</td>\n",
       "      <td>Sulfur production in the United States was pri...</td>\n",
       "      <td>Sulfur production in the United States was pri...</td>\n",
       "      <td>Sulfur production in the United States was pri...</td>\n",
       "      <td>Sulfur production in the United States was pri...</td>\n",
       "      <td>A</td>\n",
       "      <td>-Sulfur dioxide is primarily produced for sulf...</td>\n",
       "      <td>How was sulfur produced in the United States i...</td>\n",
       "      <td>A E B</td>\n",
       "      <td>[(array(0.754821, dtype=float32), 'A'), (array...</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "      <td>0.754821</td>\n",
       "      <td>0.026441</td>\n",
       "      <td>0.006280</td>\n",
       "      <td>0.018604</td>\n",
       "      <td>0.193854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>What is a fexpr in Lisp programming languages?</td>\n",
       "      <td>A fexpr is a function that requires the evalua...</td>\n",
       "      <td>A fexpr is a function that automatically evalu...</td>\n",
       "      <td>A fexpr is a function that does not require th...</td>\n",
       "      <td>A fexpr is a function that passes its operands...</td>\n",
       "      <td>A fexpr is a function that only evaluates the ...</td>\n",
       "      <td>C</td>\n",
       "      <td>-In Lisp programming languages, a fexpr is a f...</td>\n",
       "      <td>What is a fexpr in Lisp programming languages?...</td>\n",
       "      <td>D C E</td>\n",
       "      <td>[(array(0.00166235, dtype=float32), 'A'), (arr...</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.027681</td>\n",
       "      <td>0.945755</td>\n",
       "      <td>0.023677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What is the height at which mountaineers are m...</td>\n",
       "      <td>6,000 feet</td>\n",
       "      <td>9,000 feet</td>\n",
       "      <td>12,000 feet</td>\n",
       "      <td>18,000 feet</td>\n",
       "      <td>15,000 feet</td>\n",
       "      <td>B</td>\n",
       "      <td>-Altitude sickness can first occur at 1,500 me...</td>\n",
       "      <td>What is the height at which mountaineers are m...</td>\n",
       "      <td>D B C</td>\n",
       "      <td>[(array(0.06164877, dtype=float32), 'A'), (arr...</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>0.061649</td>\n",
       "      <td>0.225502</td>\n",
       "      <td>0.208555</td>\n",
       "      <td>0.455526</td>\n",
       "      <td>0.048768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>1265</td>\n",
       "      <td>What is the relation between the three moment ...</td>\n",
       "      <td>The three moment theorem expresses the relatio...</td>\n",
       "      <td>The three moment theorem is used to calculate ...</td>\n",
       "      <td>The three moment theorem describes the relatio...</td>\n",
       "      <td>The three moment theorem is used to calculate ...</td>\n",
       "      <td>The three moment theorem is used to derive the...</td>\n",
       "      <td>C</td>\n",
       "      <td>-In civil engineering and structural analysis ...</td>\n",
       "      <td>What is the relation between the three moment ...</td>\n",
       "      <td>C E A</td>\n",
       "      <td>[(array(0.00655538, dtype=float32), 'A'), (arr...</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>0.006555</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.935633</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.055318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>1266</td>\n",
       "      <td>What is the throttling process, and why is it ...</td>\n",
       "      <td>The throttling process is a steady flow of a f...</td>\n",
       "      <td>The throttling process is a steady adiabatic f...</td>\n",
       "      <td>The throttling process is a steady adiabatic f...</td>\n",
       "      <td>The throttling process is a steady flow of a f...</td>\n",
       "      <td>The throttling process is a steady adiabatic f...</td>\n",
       "      <td>B</td>\n",
       "      <td>-Throttling One of the simple applications of ...</td>\n",
       "      <td>What is the throttling process, and why is it ...</td>\n",
       "      <td>E B C</td>\n",
       "      <td>[(array(0.01305553, dtype=float32), 'A'), (arr...</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>0.013056</td>\n",
       "      <td>0.344691</td>\n",
       "      <td>0.130830</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.509421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>1267</td>\n",
       "      <td>What happens to excess base metal as a solutio...</td>\n",
       "      <td>The excess base metal will often solidify, bec...</td>\n",
       "      <td>The excess base metal will often crystallize-o...</td>\n",
       "      <td>The excess base metal will often dissolve, bec...</td>\n",
       "      <td>The excess base metal will often liquefy, beco...</td>\n",
       "      <td>The excess base metal will often evaporate, be...</td>\n",
       "      <td>B</td>\n",
       "      <td>-Similarly, a hypoeutectoid alloy has two crit...</td>\n",
       "      <td>What happens to excess base metal as a solutio...</td>\n",
       "      <td>B A C</td>\n",
       "      <td>[(array(0.110943, dtype=float32), 'A'), (array...</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>0.110943</td>\n",
       "      <td>0.859105</td>\n",
       "      <td>0.020683</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.006358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>1268</td>\n",
       "      <td>What is the relationship between mass, force, ...</td>\n",
       "      <td>Mass is a property that determines the weight ...</td>\n",
       "      <td>Mass is an inertial property that determines a...</td>\n",
       "      <td>Mass is an inertial property that determines a...</td>\n",
       "      <td>Mass is an inertial property that determines a...</td>\n",
       "      <td>Mass is a property that determines the size of...</td>\n",
       "      <td>D</td>\n",
       "      <td>-Mass is (among other properties) an inertial ...</td>\n",
       "      <td>What is the relationship between mass, force, ...</td>\n",
       "      <td>D C A</td>\n",
       "      <td>[(array(0.06352976, dtype=float32), 'A'), (arr...</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>0.063530</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.132407</td>\n",
       "      <td>0.773951</td>\n",
       "      <td>0.002140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>1269</td>\n",
       "      <td>What did Arthur Eddington discover about two o...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>Arthur Eddington showed that two of Einstein's...</td>\n",
       "      <td>C</td>\n",
       "      <td>-The possibility of gravitational waves was di...</td>\n",
       "      <td>What did Arthur Eddington discover about two o...</td>\n",
       "      <td>A C E</td>\n",
       "      <td>[(array(0.5981175, dtype=float32), 'A'), (arra...</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>0.598117</td>\n",
       "      <td>0.007529</td>\n",
       "      <td>0.300752</td>\n",
       "      <td>0.036201</td>\n",
       "      <td>0.057400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1270 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             prompt  \\\n",
       "0        0  What does a diffusion-limited enzyme represent...   \n",
       "1        1  What are known clusters of neurons in the medu...   \n",
       "2        2  How was sulfur produced in the United States i...   \n",
       "3        3     What is a fexpr in Lisp programming languages?   \n",
       "4        4  What is the height at which mountaineers are m...   \n",
       "...    ...                                                ...   \n",
       "1265  1265  What is the relation between the three moment ...   \n",
       "1266  1266  What is the throttling process, and why is it ...   \n",
       "1267  1267  What happens to excess base metal as a solutio...   \n",
       "1268  1268  What is the relationship between mass, force, ...   \n",
       "1269  1269  What did Arthur Eddington discover about two o...   \n",
       "\n",
       "                                                      A  \\\n",
       "0                     An intrinsic, physical constraint   \n",
       "1                                         baroreceptors   \n",
       "2     Sulfur production in the United States was pri...   \n",
       "3     A fexpr is a function that requires the evalua...   \n",
       "4                                            6,000 feet   \n",
       "...                                                 ...   \n",
       "1265  The three moment theorem expresses the relatio...   \n",
       "1266  The throttling process is a steady flow of a f...   \n",
       "1267  The excess base metal will often solidify, bec...   \n",
       "1268  Mass is a property that determines the weight ...   \n",
       "1269  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                      B  \\\n",
       "0        A maximum peak height in the fitness landscape   \n",
       "1                                        angioreceptors   \n",
       "2     Sulfur production in the United States was pri...   \n",
       "3     A fexpr is a function that automatically evalu...   \n",
       "4                                            9,000 feet   \n",
       "...                                                 ...   \n",
       "1265  The three moment theorem is used to calculate ...   \n",
       "1266  The throttling process is a steady adiabatic f...   \n",
       "1267  The excess base metal will often crystallize-o...   \n",
       "1268  Mass is an inertial property that determines a...   \n",
       "1269  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                      C  \\\n",
       "0                            An evolutionary limitation   \n",
       "1                             the cardiomotor mechanism   \n",
       "2     Sulfur production in the United States was pri...   \n",
       "3     A fexpr is a function that does not require th...   \n",
       "4                                           12,000 feet   \n",
       "...                                                 ...   \n",
       "1265  The three moment theorem describes the relatio...   \n",
       "1266  The throttling process is a steady adiabatic f...   \n",
       "1267  The excess base metal will often dissolve, bec...   \n",
       "1268  Mass is an inertial property that determines a...   \n",
       "1269  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                      D  \\\n",
       "0                                 A chemical limitation   \n",
       "1                             the cardiovascular center   \n",
       "2     Sulfur production in the United States was pri...   \n",
       "3     A fexpr is a function that passes its operands...   \n",
       "4                                           18,000 feet   \n",
       "...                                                 ...   \n",
       "1265  The three moment theorem is used to calculate ...   \n",
       "1266  The throttling process is a steady flow of a f...   \n",
       "1267  The excess base metal will often liquefy, beco...   \n",
       "1268  Mass is an inertial property that determines a...   \n",
       "1269  Arthur Eddington showed that two of Einstein's...   \n",
       "\n",
       "                                                      E answer  \\\n",
       "0                                A diffusion limitation      B   \n",
       "1                                        angioreceptors      D   \n",
       "2     Sulfur production in the United States was pri...      A   \n",
       "3     A fexpr is a function that only evaluates the ...      C   \n",
       "4                                           15,000 feet      B   \n",
       "...                                                 ...    ...   \n",
       "1265  The three moment theorem is used to derive the...      C   \n",
       "1266  The throttling process is a steady adiabatic f...      B   \n",
       "1267  The excess base metal will often evaporate, be...      B   \n",
       "1268  Mass is a property that determines the size of...      D   \n",
       "1269  Arthur Eddington showed that two of Einstein's...      C   \n",
       "\n",
       "                                                context  \\\n",
       "0     -A diffusion-limited enzyme catalyses a reacti...   \n",
       "1     -Regulation of blood pressure The endogenous, ...   \n",
       "2     -Sulfur dioxide is primarily produced for sulf...   \n",
       "3     -In Lisp programming languages, a fexpr is a f...   \n",
       "4     -Altitude sickness can first occur at 1,500 me...   \n",
       "...                                                 ...   \n",
       "1265  -In civil engineering and structural analysis ...   \n",
       "1266  -Throttling One of the simple applications of ...   \n",
       "1267  -Similarly, a hypoeutectoid alloy has two crit...   \n",
       "1268  -Mass is (among other properties) an inertial ...   \n",
       "1269  -The possibility of gravitational waves was di...   \n",
       "\n",
       "                                            instruction prediction  \\\n",
       "0     What does a diffusion-limited enzyme represent...      A B C   \n",
       "1     What are known clusters of neurons in the medu...      D C A   \n",
       "2     How was sulfur produced in the United States i...      A E B   \n",
       "3     What is a fexpr in Lisp programming languages?...      D C E   \n",
       "4     What is the height at which mountaineers are m...      D B C   \n",
       "...                                                 ...        ...   \n",
       "1265  What is the relation between the three moment ...      C E A   \n",
       "1266  What is the throttling process, and why is it ...      E B C   \n",
       "1267  What happens to excess base metal as a solutio...      B A C   \n",
       "1268  What is the relationship between mass, force, ...      D C A   \n",
       "1269  What did Arthur Eddington discover about two o...      A C E   \n",
       "\n",
       "                                                 logits lora_choice_1  \\\n",
       "0     [(array(0.53893685, dtype=float32), 'A'), (arr...             A   \n",
       "1     [(array(0.03887285, dtype=float32), 'A'), (arr...             D   \n",
       "2     [(array(0.754821, dtype=float32), 'A'), (array...             A   \n",
       "3     [(array(0.00166235, dtype=float32), 'A'), (arr...             D   \n",
       "4     [(array(0.06164877, dtype=float32), 'A'), (arr...             D   \n",
       "...                                                 ...           ...   \n",
       "1265  [(array(0.00655538, dtype=float32), 'A'), (arr...             C   \n",
       "1266  [(array(0.01305553, dtype=float32), 'A'), (arr...             E   \n",
       "1267  [(array(0.110943, dtype=float32), 'A'), (array...             B   \n",
       "1268  [(array(0.06352976, dtype=float32), 'A'), (arr...             D   \n",
       "1269  [(array(0.5981175, dtype=float32), 'A'), (arra...             A   \n",
       "\n",
       "     lora_choice_2 lora_choice_3    A_prob    B_prob    C_prob    D_prob  \\\n",
       "0                B             C  0.538937  0.453830  0.004115  0.001016   \n",
       "1                C             A  0.038873  0.014987  0.095463  0.837657   \n",
       "2                E             B  0.754821  0.026441  0.006280  0.018604   \n",
       "3                C             E  0.001662  0.001226  0.027681  0.945755   \n",
       "4                B             C  0.061649  0.225502  0.208555  0.455526   \n",
       "...            ...           ...       ...       ...       ...       ...   \n",
       "1265             E             A  0.006555  0.000228  0.935633  0.002265   \n",
       "1266             B             C  0.013056  0.344691  0.130830  0.002002   \n",
       "1267             A             C  0.110943  0.859105  0.020683  0.002911   \n",
       "1268             C             A  0.063530  0.027972  0.132407  0.773951   \n",
       "1269             C             E  0.598117  0.007529  0.300752  0.036201   \n",
       "\n",
       "        E_prob  \n",
       "0     0.002102  \n",
       "1     0.013021  \n",
       "2     0.193854  \n",
       "3     0.023677  \n",
       "4     0.048768  \n",
       "...        ...  \n",
       "1265  0.055318  \n",
       "1266  0.509421  \n",
       "1267  0.006358  \n",
       "1268  0.002140  \n",
       "1269  0.057400  \n",
       "\n",
       "[1270 rows x 20 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac6ef06f-f3f7-450b-8ad4-3d71bec9e874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'prompt', 'context', 'answer', 'A_weighted_prob',\n",
       "       'B_weighted_prob', 'C_weighted_prob', 'D_weighted_prob',\n",
       "       'E_weighted_prob', 'prediction', 'deberta_choice_1', 'deberta_choice_2',\n",
       "       'deberta_choice_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weighted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2e84a3d7-ef5a-4e37-a2f4-5d3f623c23d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on 'id'\n",
    "merged_df = pd.merge(df_lora, df_weighted[['id','deberta_choice_1', 'deberta_choice_2',\n",
    "       'deberta_choice_3','A_weighted_prob',\n",
    "       'B_weighted_prob', 'C_weighted_prob', 'D_weighted_prob',\n",
    "       'E_weighted_prob']], on='id', suffixes=('_lora', '_deberta'))\n",
    "\n",
    "# Define weights\n",
    "weight_lora = 0.5\n",
    "weight_deberta = 0.5\n",
    "\n",
    "# Calculate weighted sum of probabilities\n",
    "for label in ['A', 'B', 'C', 'D', 'E']:\n",
    "    merged_df[f'{label}_prob_combined'] = weight_lora * merged_df[f'{label}_prob'] + weight_deberta * merged_df[f'{label}_weighted_prob']\n",
    "\n",
    "# Keep only the 'id' and combined probability columns\n",
    "final_df = merged_df[['id'] + ['answer']+[f'{label}_prob_combined' for label in ['A', 'B', 'C', 'D', 'E']]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "00845f84-44de-47e3-ab50-ba5f444d364f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'answer', 'A_prob_combined', 'B_prob_combined', 'C_prob_combined',\n",
       "       'D_prob_combined', 'E_prob_combined'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d11d4e6-d63c-4896-8908-86247d80cb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7b179800-fc38-4581-89c2-c8ca61ff0e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1228688/3266638769.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  predictions_as_string = final_df['prediction'] = [\n"
     ]
    }
   ],
   "source": [
    "predictions_as_ids = np.argsort(-final_df[['A_prob_combined', 'B_prob_combined', 'C_prob_combined',\n",
    "       'D_prob_combined', 'E_prob_combined']].values, 1)\n",
    "\n",
    "predictions_as_answer_letters = np.array(list('ABCDE'))[predictions_as_ids]\n",
    "\n",
    "predictions_as_string = final_df['prediction'] = [\n",
    "    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "11bca56d-b6db-45d7-91c6-df87257f1c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 1 :0.85 , TOP 2 :0.09, TOP 3 :0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1228688/277629899.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['top_choice_1'] = final_df['prediction'].str[0]\n",
      "/tmp/ipykernel_1228688/277629899.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['top_choice_2'] = final_df['prediction'].str[2]\n",
      "/tmp/ipykernel_1228688/277629899.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df['top_choice_3'] = final_df['prediction'].str[4]\n"
     ]
    }
   ],
   "source": [
    "final_df['top_choice_1'] = final_df['prediction'].str[0]\n",
    "final_df['top_choice_2'] = final_df['prediction'].str[2]\n",
    "final_df['top_choice_3'] = final_df['prediction'].str[4]\n",
    "\n",
    "\n",
    "top1_prob_combined = accuracy_score(final_df['answer'].values,final_df['top_choice_1'].values )\n",
    "top2_prob_combined = accuracy_score(final_df['answer'].values,final_df['top_choice_2'].values )\n",
    "top3_prob_combined = accuracy_score(final_df['answer'].values,final_df['top_choice_3'].values )\n",
    "print(f\"TOP 1 :{round(top1_prob_combined,2)} , TOP 2 :{round(top2_prob_combined,2)}, TOP 3 :{round(top3_prob_combined,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0ac33799-0509-4114-91ce-3864d98e16f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAP@3 = 0.9095800524934389\n"
     ]
    }
   ],
   "source": [
    "m = MAP_at_3(final_df.prediction.values, final_df.answer.values)\n",
    "print( 'CV MAP@3 =',m )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb6b51-f419-44b9-bf79-588700a13598",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_probs = df_lora[['id','A_prob', 'B_prob', 'C_prob', 'D_prob', 'E_prob']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1286d456-ede3-4d65-9ee4-4c8811236f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_match = df_lora.merge(df_deberta_context[['id','deberta_choice_1', 'deberta_choice_2',\n",
    "       'deberta_choice_3','A_prob', 'B_prob', 'C_prob', 'D_prob', 'E_prob']], on=['id'],how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37a6296b-e4e9-44a0-86cf-068ed6709ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    179\n",
       "True     121\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((master_match['deberta_choice_1'] == master_match['lora_choice_1']) & (master_match['lora_choice_1'] == master_match['answer'])).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a21e7e4d-280e-406c-8509-9f636ac72c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     158\n",
       "False    142\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(master_match['deberta_choice_1'] == master_match['lora_choice_1']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78cb7f49-e0ce-4e52-a30f-c87b806ecffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 17), (300, 13))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_match.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36081a97-402d-4378-b48d-b4c6aa0ba73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del master_match[\"deberta_lora\"] #= master_match.apply(lambda row: ' '.join(row['deberta_choice_1']+row['lora_choice_2']+row['lora_choice_3']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0d16833-48b6-4bc2-bba0-ffd34acea6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_match.to_csv('./master_match.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4954eef6-52a7-4abb-aa1c-5aecf4afee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the issue in the implementation to avoid duplication in the prediction string\n",
    "for index, row in master_match.iterrows():\n",
    "    prediction_values = []\n",
    "    added_choices = set()\n",
    "    \n",
    "    if row['deberta_choice_1'] not in added_choices:\n",
    "        prediction_values.append(row['deberta_choice_1'])\n",
    "        added_choices.add(row['deberta_choice_1'])\n",
    "        \n",
    "    if row['lora_choice_1'] not in added_choices and len(prediction_values) < 3:\n",
    "        prediction_values.append(row['lora_choice_1'])\n",
    "        added_choices.add(row['lora_choice_1'])\n",
    "        \n",
    "    if row['lora_choice_2'] not in added_choices and len(prediction_values) < 3:\n",
    "        prediction_values.append(row['lora_choice_2'])\n",
    "        added_choices.add(row['lora_choice_2'])\n",
    "    \n",
    "    if row['deberta_choice_2'] not in added_choices and len(prediction_values) < 3:\n",
    "        prediction_values.append(row['deberta_choice_2'])\n",
    "        added_choices.add(row['deberta_choice_2'])\n",
    "        \n",
    "    if row['lora_choice_3'] not in added_choices and len(prediction_values) < 3:\n",
    "        prediction_values.append(row['lora_choice_3'])\n",
    "        added_choices.add(row['lora_choice_3'])\n",
    "        \n",
    "    if row['deberta_choice_3'] not in added_choices and len(prediction_values) < 3:\n",
    "        prediction_values.append(row['deberta_choice_3'])\n",
    "        added_choices.add(row['deberta_choice_3'])\n",
    "    \n",
    "    # Join the top 3 non-unique values to form the prediction string\n",
    "    master_match.at[index, 'deberta_lora'] = ' '.join(prediction_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "968a2f8a-684b-409d-bdea-e2d875687a38",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>context</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>id</th>\n",
       "      <th>instruction</th>\n",
       "      <th>prediction</th>\n",
       "      <th>answer</th>\n",
       "      <th>lora_choice_1</th>\n",
       "      <th>lora_choice_2</th>\n",
       "      <th>lora_choice_3</th>\n",
       "      <th>deberta_choice_1</th>\n",
       "      <th>deberta_choice_2</th>\n",
       "      <th>deberta_choice_3</th>\n",
       "      <th>deberta_lora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the method of transcription in the lif...</td>\n",
       "      <td>DNA-templated transcription is the method of t...</td>\n",
       "      <td>RNA-templated transcription is the method of t...</td>\n",
       "      <td>Transcription occurs through a unique mechanis...</td>\n",
       "      <td>Reverse transcription is the method of transcr...</td>\n",
       "      <td>DNA-templated transcription is the method of t...</td>\n",
       "      <td>Transcription does not occur in the life cycle...</td>\n",
       "      <td>0</td>\n",
       "      <td>What is the method of transcription in the lif...</td>\n",
       "      <td>A C D</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>D A C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the role of the viral fiber glycoprote...</td>\n",
       "      <td>Entry into the host cell is achieved by attach...</td>\n",
       "      <td>The viral fiber glycoproteins are involved in ...</td>\n",
       "      <td>The viral fiber glycoproteins code for 40 prot...</td>\n",
       "      <td>The viral fiber glycoproteins are responsible ...</td>\n",
       "      <td>The viral fiber glycoproteins mediate endocyto...</td>\n",
       "      <td>The viral fiber glycoproteins are responsible ...</td>\n",
       "      <td>1</td>\n",
       "      <td>What is the role of the viral fiber glycoprote...</td>\n",
       "      <td>C D A</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>D C B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the significance of the faint Hα emiss...</td>\n",
       "      <td>Gamma Geminorum (γ Geminorum, abbreviated Gamm...</td>\n",
       "      <td>The emission lines indicate that 3 Geminorum i...</td>\n",
       "      <td>The emission lines indicate that 3 Geminorum i...</td>\n",
       "      <td>The emission lines indicate that 3 Geminorum i...</td>\n",
       "      <td>The emission lines indicate that 3 Geminorum i...</td>\n",
       "      <td>The emission lines indicate that 3 Geminorum i...</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the significance of the faint Hα emiss...</td>\n",
       "      <td>B C E</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>B C E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the significance of the pedicellariae ...</td>\n",
       "      <td>Peziza vesiculosa is a species of apothecial f...</td>\n",
       "      <td>They are used for climbing on corals.</td>\n",
       "      <td>They resemble the traps of the Venus fly trap ...</td>\n",
       "      <td>They are covered by short and stout spines.</td>\n",
       "      <td>They are found on the central disc of the sea ...</td>\n",
       "      <td>They are a characteristic feature of the Gonia...</td>\n",
       "      <td>3</td>\n",
       "      <td>What is the significance of the pedicellariae ...</td>\n",
       "      <td>C B A</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C B A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the role of the microprocessor complex...</td>\n",
       "      <td>The microprocessor complex is a protein comple...</td>\n",
       "      <td>The microprocessor complex is responsible for ...</td>\n",
       "      <td>The microprocessor complex is responsible for ...</td>\n",
       "      <td>The microprocessor complex is involved in the ...</td>\n",
       "      <td>The microprocessor complex is involved in the ...</td>\n",
       "      <td>The microprocessor complex is responsible for ...</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the role of the microprocessor complex...</td>\n",
       "      <td>A D B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>A D B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>What is the significance of the anti-de Sitter...</td>\n",
       "      <td>This observation is the starting point for AdS...</td>\n",
       "      <td>The AdS/CFT correspondence is a conjectured re...</td>\n",
       "      <td>The AdS/CFT correspondence provides a non-pert...</td>\n",
       "      <td>The AdS/CFT correspondence represents a major ...</td>\n",
       "      <td>The AdS/CFT correspondence is a strong-weak du...</td>\n",
       "      <td>The AdS/CFT correspondence was first proposed ...</td>\n",
       "      <td>295</td>\n",
       "      <td>What is the significance of the anti-de Sitter...</td>\n",
       "      <td>D A C</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>A D C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>What is the branch of physics that seeks to de...</td>\n",
       "      <td>String theories are quantum theories of gravit...</td>\n",
       "      <td>String theory</td>\n",
       "      <td>Quantum gravity</td>\n",
       "      <td>AdS/CFT correspondence</td>\n",
       "      <td>General relativity</td>\n",
       "      <td>M-theory</td>\n",
       "      <td>296</td>\n",
       "      <td>What is the branch of physics that seeks to de...</td>\n",
       "      <td>C A B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>B C A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>What is the AdS/CFT correspondence according t...</td>\n",
       "      <td>The conformal field theory is like a hologram ...</td>\n",
       "      <td>The AdS/CFT correspondence is a relationship b...</td>\n",
       "      <td>The AdS/CFT correspondence is the theory that ...</td>\n",
       "      <td>The AdS/CFT correspondence is a dictionary tha...</td>\n",
       "      <td>The AdS/CFT correspondence is the equivalence ...</td>\n",
       "      <td>The AdS/CFT correspondence is a mathematical c...</td>\n",
       "      <td>297</td>\n",
       "      <td>What is the AdS/CFT correspondence according t...</td>\n",
       "      <td>B C D</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>B C D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>What is the purpose of superstring theory acco...</td>\n",
       "      <td>Superstring theory is an attempt to explain al...</td>\n",
       "      <td>To explain the behavior of fundamental particl...</td>\n",
       "      <td>To explain the behavior of large-scale structu...</td>\n",
       "      <td>To describe the four fundamental forces acting...</td>\n",
       "      <td>To harmonize the theory of general relativity ...</td>\n",
       "      <td>To eliminate the infinities in quantum field t...</td>\n",
       "      <td>298</td>\n",
       "      <td>What is the purpose of superstring theory acco...</td>\n",
       "      <td>E A D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>E</td>\n",
       "      <td>A E D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>What is the role of T-duality in string/M-theory?</td>\n",
       "      <td>Ashoke Sen studied S-duality in the context of...</td>\n",
       "      <td>T-duality reveals the existence of mirror symm...</td>\n",
       "      <td>T-duality transforms compact dimensions of rad...</td>\n",
       "      <td>T-duality unifies gauge and gravity interactio...</td>\n",
       "      <td>T-duality exchanges momentum modes for winding...</td>\n",
       "      <td>T-duality explains the compactification of the...</td>\n",
       "      <td>299</td>\n",
       "      <td>What is the role of T-duality in string/M-theo...</td>\n",
       "      <td>B A D</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D B A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt  \\\n",
       "0    What is the method of transcription in the lif...   \n",
       "1    What is the role of the viral fiber glycoprote...   \n",
       "2    What is the significance of the faint Hα emiss...   \n",
       "3    What is the significance of the pedicellariae ...   \n",
       "4    What is the role of the microprocessor complex...   \n",
       "..                                                 ...   \n",
       "295  What is the significance of the anti-de Sitter...   \n",
       "296  What is the branch of physics that seeks to de...   \n",
       "297  What is the AdS/CFT correspondence according t...   \n",
       "298  What is the purpose of superstring theory acco...   \n",
       "299  What is the role of T-duality in string/M-theory?   \n",
       "\n",
       "                                               context  \\\n",
       "0    DNA-templated transcription is the method of t...   \n",
       "1    Entry into the host cell is achieved by attach...   \n",
       "2    Gamma Geminorum (γ Geminorum, abbreviated Gamm...   \n",
       "3    Peziza vesiculosa is a species of apothecial f...   \n",
       "4    The microprocessor complex is a protein comple...   \n",
       "..                                                 ...   \n",
       "295  This observation is the starting point for AdS...   \n",
       "296  String theories are quantum theories of gravit...   \n",
       "297  The conformal field theory is like a hologram ...   \n",
       "298  Superstring theory is an attempt to explain al...   \n",
       "299  Ashoke Sen studied S-duality in the context of...   \n",
       "\n",
       "                                                     A  \\\n",
       "0    RNA-templated transcription is the method of t...   \n",
       "1    The viral fiber glycoproteins are involved in ...   \n",
       "2    The emission lines indicate that 3 Geminorum i...   \n",
       "3                They are used for climbing on corals.   \n",
       "4    The microprocessor complex is responsible for ...   \n",
       "..                                                 ...   \n",
       "295  The AdS/CFT correspondence is a conjectured re...   \n",
       "296                                      String theory   \n",
       "297  The AdS/CFT correspondence is a relationship b...   \n",
       "298  To explain the behavior of fundamental particl...   \n",
       "299  T-duality reveals the existence of mirror symm...   \n",
       "\n",
       "                                                     B  \\\n",
       "0    Transcription occurs through a unique mechanis...   \n",
       "1    The viral fiber glycoproteins code for 40 prot...   \n",
       "2    The emission lines indicate that 3 Geminorum i...   \n",
       "3    They resemble the traps of the Venus fly trap ...   \n",
       "4    The microprocessor complex is responsible for ...   \n",
       "..                                                 ...   \n",
       "295  The AdS/CFT correspondence provides a non-pert...   \n",
       "296                                    Quantum gravity   \n",
       "297  The AdS/CFT correspondence is the theory that ...   \n",
       "298  To explain the behavior of large-scale structu...   \n",
       "299  T-duality transforms compact dimensions of rad...   \n",
       "\n",
       "                                                     C  \\\n",
       "0    Reverse transcription is the method of transcr...   \n",
       "1    The viral fiber glycoproteins are responsible ...   \n",
       "2    The emission lines indicate that 3 Geminorum i...   \n",
       "3          They are covered by short and stout spines.   \n",
       "4    The microprocessor complex is involved in the ...   \n",
       "..                                                 ...   \n",
       "295  The AdS/CFT correspondence represents a major ...   \n",
       "296                             AdS/CFT correspondence   \n",
       "297  The AdS/CFT correspondence is a dictionary tha...   \n",
       "298  To describe the four fundamental forces acting...   \n",
       "299  T-duality unifies gauge and gravity interactio...   \n",
       "\n",
       "                                                     D  \\\n",
       "0    DNA-templated transcription is the method of t...   \n",
       "1    The viral fiber glycoproteins mediate endocyto...   \n",
       "2    The emission lines indicate that 3 Geminorum i...   \n",
       "3    They are found on the central disc of the sea ...   \n",
       "4    The microprocessor complex is involved in the ...   \n",
       "..                                                 ...   \n",
       "295  The AdS/CFT correspondence is a strong-weak du...   \n",
       "296                                 General relativity   \n",
       "297  The AdS/CFT correspondence is the equivalence ...   \n",
       "298  To harmonize the theory of general relativity ...   \n",
       "299  T-duality exchanges momentum modes for winding...   \n",
       "\n",
       "                                                     E   id  \\\n",
       "0    Transcription does not occur in the life cycle...    0   \n",
       "1    The viral fiber glycoproteins are responsible ...    1   \n",
       "2    The emission lines indicate that 3 Geminorum i...    2   \n",
       "3    They are a characteristic feature of the Gonia...    3   \n",
       "4    The microprocessor complex is responsible for ...    4   \n",
       "..                                                 ...  ...   \n",
       "295  The AdS/CFT correspondence was first proposed ...  295   \n",
       "296                                           M-theory  296   \n",
       "297  The AdS/CFT correspondence is a mathematical c...  297   \n",
       "298  To eliminate the infinities in quantum field t...  298   \n",
       "299  T-duality explains the compactification of the...  299   \n",
       "\n",
       "                                           instruction prediction answer  \\\n",
       "0    What is the method of transcription in the lif...      A C D      D   \n",
       "1    What is the role of the viral fiber glycoprote...      C D A      D   \n",
       "2    What is the significance of the faint Hα emiss...      B C E      A   \n",
       "3    What is the significance of the pedicellariae ...      C B A      B   \n",
       "4    What is the role of the microprocessor complex...      A D B      A   \n",
       "..                                                 ...        ...    ...   \n",
       "295  What is the significance of the anti-de Sitter...      D A C      C   \n",
       "296  What is the branch of physics that seeks to de...      C A B      B   \n",
       "297  What is the AdS/CFT correspondence according t...      B C D      D   \n",
       "298  What is the purpose of superstring theory acco...      E A D      A   \n",
       "299  What is the role of T-duality in string/M-theo...      B A D      A   \n",
       "\n",
       "    lora_choice_1 lora_choice_2 lora_choice_3 deberta_choice_1  \\\n",
       "0               A             C             D                D   \n",
       "1               C             D             A                D   \n",
       "2               B             C             E                B   \n",
       "3               C             B             A                C   \n",
       "4               A             D             B                A   \n",
       "..            ...           ...           ...              ...   \n",
       "295             D             A             C                A   \n",
       "296             C             A             B                B   \n",
       "297             B             C             D                B   \n",
       "298             E             A             D                A   \n",
       "299             B             A             D                D   \n",
       "\n",
       "    deberta_choice_2 deberta_choice_3 deberta_lora  \n",
       "0                  A                C        D A C  \n",
       "1                  B                C        D C B  \n",
       "2                  E                C        B C E  \n",
       "3                  A                E        C B A  \n",
       "4                  D                C        A D B  \n",
       "..               ...              ...          ...  \n",
       "295                C                B        A D C  \n",
       "296                A                E        B C A  \n",
       "297                D                C        B C D  \n",
       "298                D                E        A E D  \n",
       "299                A                B        D B A  \n",
       "\n",
       "[300 rows x 18 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c726413b-d682-457e-9916-8b8ecd46187d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eba6d481-9f19-4506-a681-10df0e3c16fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAP@3 = 0.7738888888888893\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print( 'CV MAP@3 =', MAP_at_3(master_match.deberta_lora.values, master_match.answer.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3ec39115-4c8a-4300-8223-c1987a76ec61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 1 :0.66 , TOP 2 :0.16, TOP 3 :0.11\n"
     ]
    }
   ],
   "source": [
    "master_match['choice_1'] = master_match['deberta_lora'].str[0]\n",
    "master_match['choice_2'] = master_match['deberta_lora'].str[2]\n",
    "master_match['choice_3'] = master_match['deberta_lora'].str[4]\n",
    "\n",
    "\n",
    "top1_mixed = accuracy_score(master_match['answer'].values,master_match['choice_1'].values )\n",
    "top2_mixed = accuracy_score(master_match['answer'].values,master_match['choice_2'].values )\n",
    "top3_mixed = accuracy_score(master_match['answer'].values,master_match['choice_3'].values )\n",
    "print(f\"TOP 1 :{round(top1_mixed,2)} , TOP 2 :{round(top2_mixed,2)}, TOP 3 :{round(top3_mixed,2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6410cf4c-7194-437d-9f98-c68c73bec7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b0339d-2163-4e8b-bf50-5fe1fb589d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f833879e-1a57-4f1c-8c4e-4089c7d26488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "\n",
    "def create_folds(data, num_splits):\n",
    "    dfx = pd.get_dummies(data, columns=[\"answer\"]).groupby([\"id\"], as_index=False).sum()\n",
    "    cols = [c for c in dfx.columns if c.startswith(\"answer\") or c == \"id\" and c != \"answer\"]\n",
    "    dfx = dfx[cols]\n",
    "    \n",
    "    mskf = MultilabelStratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "    labels = [c for c in dfx.columns if c != \"id\"]\n",
    "    dfx_labels = dfx[labels]\n",
    "    dfx[\"kfold\"] = -1\n",
    "    \n",
    "    for fold, (trn_, val_) in enumerate(mskf.split(dfx, dfx_labels)):\n",
    "        dfx.loc[val_, \"kfold\"] = fold\n",
    "    \n",
    "    data = data.merge(dfx[[\"id\", \"kfold\"]], on=\"id\", how=\"left\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a5f13c12-7af1-40c1-9c1d-bcb7634ff6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>context</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In relation to Eunice Fay McKenzie's career, w...</td>\n",
       "      <td>Eunice Fay McKenzie (February 19, 1918 – April...</td>\n",
       "      <td>McKenzie showcased her singing talents in nume...</td>\n",
       "      <td>McKenzie is primarily remembered for her starr...</td>\n",
       "      <td>McKenzie gained recognition for her role as a ...</td>\n",
       "      <td>McKenzie's collaborations with director Blake ...</td>\n",
       "      <td>McKenzie's successful career in sound films co...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does Modified Newtonian Dynamics (MOND) im...</td>\n",
       "      <td>The presence of a clustered thick disk-like co...</td>\n",
       "      <td>MOND is a theory that increases the discrepanc...</td>\n",
       "      <td>MOND explains the missing baryonic mass in gal...</td>\n",
       "      <td>MOND is a theory that reduces the observed mis...</td>\n",
       "      <td>MOND is a theory that eliminates the observed ...</td>\n",
       "      <td>MOND's impact on the observed missing baryonic...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which of the following statements accurately d...</td>\n",
       "      <td>Woody Hartman is a retired American soccer goa...</td>\n",
       "      <td>Ray Montgomerie is a former footballer who pla...</td>\n",
       "      <td>Ray Montgomerie is a former footballer who pla...</td>\n",
       "      <td>Ray Montgomerie is a former footballer who pla...</td>\n",
       "      <td>Ray Montgomerie is a former footballer who pla...</td>\n",
       "      <td>Ray Montgomerie is a former footballer who pla...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the significance of the Museum of the ...</td>\n",
       "      <td>The Museum of the Occupation of Latvia () is a...</td>\n",
       "      <td>The Museum of the Occupation of Latvia is a me...</td>\n",
       "      <td>The Museum of the Occupation of Latvia showcas...</td>\n",
       "      <td>The Museum of the Occupation of Latvia was est...</td>\n",
       "      <td>The Museum of the Occupation of Latvia primari...</td>\n",
       "      <td>The Museum of the Occupation of Latvia is a mu...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was the previous name of the Christian Sc...</td>\n",
       "      <td>It was named the Evangelical School for the De...</td>\n",
       "      <td>The Christian School for the Deaf (CSD)</td>\n",
       "      <td>The Christian School for the Blind (CSB)</td>\n",
       "      <td>The Evangelical School and Chapel for the Deaf...</td>\n",
       "      <td>The Evangelical School for the Deaf (ESD)</td>\n",
       "      <td>The Evangelical School for the Blind (ESB)</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  In relation to Eunice Fay McKenzie's career, w...   \n",
       "1  How does Modified Newtonian Dynamics (MOND) im...   \n",
       "2  Which of the following statements accurately d...   \n",
       "3  What is the significance of the Museum of the ...   \n",
       "4  What was the previous name of the Christian Sc...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Eunice Fay McKenzie (February 19, 1918 – April...   \n",
       "1  The presence of a clustered thick disk-like co...   \n",
       "2  Woody Hartman is a retired American soccer goa...   \n",
       "3  The Museum of the Occupation of Latvia () is a...   \n",
       "4  It was named the Evangelical School for the De...   \n",
       "\n",
       "                                                   A  \\\n",
       "0  McKenzie showcased her singing talents in nume...   \n",
       "1  MOND is a theory that increases the discrepanc...   \n",
       "2  Ray Montgomerie is a former footballer who pla...   \n",
       "3  The Museum of the Occupation of Latvia is a me...   \n",
       "4            The Christian School for the Deaf (CSD)   \n",
       "\n",
       "                                                   B  \\\n",
       "0  McKenzie is primarily remembered for her starr...   \n",
       "1  MOND explains the missing baryonic mass in gal...   \n",
       "2  Ray Montgomerie is a former footballer who pla...   \n",
       "3  The Museum of the Occupation of Latvia showcas...   \n",
       "4           The Christian School for the Blind (CSB)   \n",
       "\n",
       "                                                   C  \\\n",
       "0  McKenzie gained recognition for her role as a ...   \n",
       "1  MOND is a theory that reduces the observed mis...   \n",
       "2  Ray Montgomerie is a former footballer who pla...   \n",
       "3  The Museum of the Occupation of Latvia was est...   \n",
       "4  The Evangelical School and Chapel for the Deaf...   \n",
       "\n",
       "                                                   D  \\\n",
       "0  McKenzie's collaborations with director Blake ...   \n",
       "1  MOND is a theory that eliminates the observed ...   \n",
       "2  Ray Montgomerie is a former footballer who pla...   \n",
       "3  The Museum of the Occupation of Latvia primari...   \n",
       "4          The Evangelical School for the Deaf (ESD)   \n",
       "\n",
       "                                                   E answer  \n",
       "0  McKenzie's successful career in sound films co...      B  \n",
       "1  MOND's impact on the observed missing baryonic...      E  \n",
       "2  Ray Montgomerie is a former footballer who pla...      B  \n",
       "3  The Museum of the Occupation of Latvia is a mu...      C  \n",
       "4         The Evangelical School for the Blind (ESB)      D  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e05f344a-c9d8-4a38-a95a-f64cfb3b82b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_actual = pd.read_csv('input_data/validation_data/stem1k/dataset_wiki_new_1_balanced.csv')\n",
    "df_train = pd.read_csv('input_data/all_12_with_context2.csv')\n",
    "df_train = df_train.drop(columns=\"source\")\n",
    "\n",
    "# df_train = df_train.fillna('')#.sample(NUM_TRAIN_SAMPLES)\n",
    "# df_train = df_train.dropna(how='any', axis=0) # delete 4 choice question\n",
    "\n",
    "\n",
    "\n",
    "# df_train = df_train.apply(make_random_4_from_3,axis=1)\n",
    "# df_train = df_train.dropna(how='any', axis=0) # delete 4 choice question\n",
    "\n",
    "\n",
    "# train[\"id\"] = list(range(len(train)))\n",
    "# train['answer'] = df_actual['answer']\n",
    "\n",
    "\n",
    "# train = create_folds(train, num_splits=4)\n",
    "# train.to_csv('./train_folds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "39ea0504-8ce2-4aa0-91d6-23c27f766082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60347, 8)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "cf6b1f64-140f-4562-9e9d-436904033fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['id'] = list(range(len(df_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b67588f6-7291-4eb2-abe1-a7549095534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_null = df_train.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "352b3c15-f34a-4e73-b5b7-078ee4375d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_fill = df_train[~df_train.id.isin(df_no_null.id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7ea91e88-3459-4ff8-ab61-bda62a5c690c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13660, 9), (46687, 9))"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_fill.shape , df_no_null.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b448302f-6031-483c-bdea-e3fb90e8dffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load pre-trained Word2Vec model (Download and specify path accordingly)\n",
    "model = KeyedVectors.load_word2vec_format('models/googelnews/GoogleNews-vectors-negative300.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c75dd83-49ff-4f95-bb24-7721fbbbb617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_options(row):\n",
    "    options = ['A', 'B', 'C', 'D', 'E']\n",
    "    available_options = {}\n",
    "    \n",
    "    # Get available options\n",
    "    for opt in options:\n",
    "        if pd.notna(row[f'{opt}']):\n",
    "            available_options[opt] = row[f'{opt}']\n",
    "    \n",
    "    # Remove the correct answer from available_options\n",
    "    correct_option = row['answer']\n",
    "    if correct_option in available_options:\n",
    "        del available_options[correct_option]\n",
    "    \n",
    "    similar_words_list = []\n",
    "    \n",
    "    # Generate similar words for available incorrect options\n",
    "    for option_word in available_options.values():\n",
    "        print(f\"Processing option_word: {option_word}\")  # Debug print\n",
    "        words = option_word.split()\n",
    "        vectors = []\n",
    "        for word in words:\n",
    "            try:\n",
    "                vectors.append(model[word])\n",
    "            except KeyError:\n",
    "                print(f\"Word '{word}' not in vocabulary.\")  # Debug print\n",
    "\n",
    "        if vectors:\n",
    "            avg_vector = sum(vectors) / len(vectors)\n",
    "            try:\n",
    "                similar_words = [item[0] for item in model.similar_by_vector(avg_vector, topn=3)]\n",
    "                print(f\"Similar words found: {similar_words}\")  # Debug print\n",
    "                similar_words_list.extend(similar_words)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in finding similar words: {e}\")  # Debug print\n",
    "\n",
    "    # Shuffle the similar words to randomize\n",
    "    random.shuffle(similar_words_list)\n",
    "    \n",
    "    # Fill missing options\n",
    "    for opt in options:\n",
    "        if pd.isna(row[f'{opt}']):\n",
    "            if similar_words_list:\n",
    "                row[f'{opt}'] = similar_words_list.pop(0)\n",
    "    \n",
    "    return row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ee762fe-3ebe-4539-857d-81989298fe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# def get_bert_embedding(word):\n",
    "#     inputs = tokenizer(word, return_tensors=\"pt\")\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#     return outputs.last_hidden_state.mean(dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ba43893-5836-48cd-bfe1-7f3be0b022ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_options(row):\n",
    "    options = ['A', 'B', 'C', 'D', 'E']\n",
    "    available_options = {opt: row[f'{opt}'] for opt in options if pd.notna(row[f'{opt}'])}\n",
    "    \n",
    "    # Remove the correct answer from available options\n",
    "    correct_option = row['answer']\n",
    "    available_options.pop(correct_option, None)\n",
    "    \n",
    "    # Generate similar words for available incorrect options\n",
    "    similar_words_list = []\n",
    "    for option_word in available_options.values():\n",
    "        try:\n",
    "            similar_words = [item[0].replace('_', ' ') for item in model.most_similar(option_word, topn=3)]\n",
    "            similar_words_list.extend(similar_words)\n",
    "        except KeyError:  # Skip words not in vocabulary\n",
    "            continue\n",
    "\n",
    "    random.shuffle(similar_words_list)\n",
    "    \n",
    "    # Fill missing options\n",
    "    for opt in options:\n",
    "        if pd.isna(row[f'{opt}']):\n",
    "            if similar_words_list:\n",
    "                row[f'{opt}'] = similar_words_list.pop(0)\n",
    "    \n",
    "    return row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36f06edc-ac47-485c-9d7e-3fc267cd4de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-05 20:49:38.856772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30550 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB, pci bus id: 0000:34:00.0, compute capability: 7.0\n",
      "2023-10-05 20:49:38.859643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30550 MB memory:  -> device: 1, name: Tesla V100-SXM3-32GB, pci bus id: 0000:36:00.0, compute capability: 7.0\n",
      "2023-10-05 20:49:38.862300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 30550 MB memory:  -> device: 2, name: Tesla V100-SXM3-32GB, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2023-10-05 20:49:38.864440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 30550 MB memory:  -> device: 3, name: Tesla V100-SXM3-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2023-10-05 20:49:38.866639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 30550 MB memory:  -> device: 4, name: Tesla V100-SXM3-32GB, pci bus id: 0000:57:00.0, compute capability: 7.0\n",
      "2023-10-05 20:49:38.868814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 30550 MB memory:  -> device: 5, name: Tesla V100-SXM3-32GB, pci bus id: 0000:59:00.0, compute capability: 7.0\n",
      "2023-10-05 20:49:38.870952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 30550 MB memory:  -> device: 6, name: Tesla V100-SXM3-32GB, pci bus id: 0000:5c:00.0, compute capability: 7.0\n",
      "2023-10-05 20:49:38.873152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 30550 MB memory:  -> device: 7, name: Tesla V100-SXM3-32GB, pci bus id: 0000:5e:00.0, compute capability: 7.0\n",
      "2023-10-05 20:49:38.875315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:8 with 5043 MB memory:  -> device: 8, name: Tesla V100-SXM3-32GB, pci bus id: 0000:b7:00.0, compute capability: 7.0\n",
      "2023-10-05 20:49:38.877526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:9 with 30550 MB memory:  -> device: 9, name: Tesla V100-SXM3-32GB, pci bus id: 0000:b9:00.0, compute capability: 7.0\n",
      "2023-10-05 20:49:38.879699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:10 with 30550 MB memory:  -> device: 10, name: Tesla V100-SXM3-32GB, pci bus id: 0000:bc:00.0, compute capability: 7.0\n",
      "2023-10-05 20:49:38.881847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:11 with 30550 MB memory:  -> device: 11, name: Tesla V100-SXM3-32GB, pci bus id: 0000:be:00.0, compute capability: 7.0\n",
      "2023-10-05 20:49:38.884011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:12 with 30550 MB memory:  -> device: 12, name: Tesla V100-SXM3-32GB, pci bus id: 0000:e0:00.0, compute capability: 7.0\n",
      "2023-10-05 20:49:38.886185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:13 with 30550 MB memory:  -> device: 13, name: Tesla V100-SXM3-32GB, pci bus id: 0000:e2:00.0, compute capability: 7.0\n",
      "2023-10-05 20:49:38.888366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:14 with 30550 MB memory:  -> device: 14, name: Tesla V100-SXM3-32GB, pci bus id: 0000:e5:00.0, compute capability: 7.0\n",
      "2023-10-05 20:49:38.890514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:15 with 30550 MB memory:  -> device: 15, name: Tesla V100-SXM3-32GB, pci bus id: 0000:e7:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sentences[most_similar_index]\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Assuming df is your DataFrame\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m df_filled \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mapply(fill_missing_sentence_options, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Load the Universal Sentence Encoder's TF Hub module\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "def fill_missing_sentence_options(row):\n",
    "    options = ['A', 'B', 'C', 'D', 'E']\n",
    "    correct_option = row['answer']\n",
    "    \n",
    "    # Filter out the available incorrect options\n",
    "    incorrect_options = [row[opt] for opt in options if pd.notna(row[opt]) and opt != correct_option]\n",
    "    \n",
    "    # If there are missing options\n",
    "    missing_options = [opt for opt in options if pd.isna(row[opt])]\n",
    "    for opt in missing_options:\n",
    "        # Get the most similar sentence from a predefined list of sentences (you can customize this list)\n",
    "        # Note: You might want to have a large diverse list of sentences for better results.\n",
    "        # Here, I'm just reusing the incorrect options for simplicity.\n",
    "        similar_sentence = get_most_similar_sentences(row[correct_option], incorrect_options)\n",
    "        row[opt] = similar_sentence\n",
    "\n",
    "    return row\n",
    "\n",
    "def get_most_similar_sentences(main_sentence, sentences):\n",
    "    \"\"\"\n",
    "    Return the most similar sentence to the main_sentence from a list of sentences.\n",
    "    \"\"\"\n",
    "    # Compute embeddings for main_sentence and list of sentences\n",
    "    main_embedding = embed([main_sentence])\n",
    "    sentences_embedding = embed(sentences)\n",
    "\n",
    "    # Compute similarity between main_sentence and each sentence in the list\n",
    "    cosine_similarities = np.inner(main_embedding, sentences_embedding).flatten()\n",
    "\n",
    "    # Get the index of the most similar sentence\n",
    "    most_similar_index = np.argmax(cosine_similarities)\n",
    "\n",
    "    return sentences[most_similar_index]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "358adabe-a6d9-463f-9216-eaca0e5b58d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "02302082-f938-4746-b12e-e7d44b14363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fill_missing_sentence_options(row):\n",
    "    options = ['A', 'B', 'C', 'D', 'E']\n",
    "    correct_option = row['answer']\n",
    "\n",
    "    # Filter out the available incorrect options\n",
    "    incorrect_options = [row[opt] for opt in options if pd.notna(row[opt]) and opt != correct_option]\n",
    "    \n",
    "    # Compute the maximum length from the available options\n",
    "    max_option_length = max(len(option) for option in incorrect_options)\n",
    "    \n",
    "    # Compute embeddings for the incorrect options\n",
    "    incorrect_embeddings = embed(incorrect_options)\n",
    "    \n",
    "    # Compute the average embedding for the missing option\n",
    "    avg_embedding = np.mean(incorrect_embeddings, axis=0)\n",
    "    \n",
    "    # Split the context into individual sentences\n",
    "    context_sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', row['context'])\n",
    "\n",
    "    # Exclude sentences which are very short or empty\n",
    "    context_sentences = [s.strip() for s in context_sentences if s and len(s.split()) > 5]\n",
    "\n",
    "    # Ensure there are valid sentences to process\n",
    "    if not context_sentences:\n",
    "        return row\n",
    "\n",
    "    # Search for a similar sentence in the context that isn't already an option\n",
    "    similar_sentence = find_similar_sentence_in_corpus(avg_embedding, context_sentences, incorrect_options + [row[correct_option]], max_option_length)\n",
    "    \n",
    "    # Fill the missing option\n",
    "    for opt in options:\n",
    "        if pd.isna(row[opt]):\n",
    "            row[opt] = similar_sentence\n",
    "\n",
    "    return row\n",
    "\n",
    "def find_similar_sentence_in_corpus(embedding, corpus, exclude_list, max_length):\n",
    "    \"\"\"\n",
    "    Find a sentence in the corpus that is most similar to the given embedding \n",
    "    but is not in the exclude_list and doesn't exceed max_length.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        corpus_embeddings = embed(corpus)\n",
    "        cosine_similarities = np.inner(embedding, corpus_embeddings).flatten()\n",
    "        sorted_indexes = np.argsort(cosine_similarities)[::-1]  # Descending order\n",
    "        \n",
    "        for idx in sorted_indexes:\n",
    "            if corpus[idx] not in exclude_list and len(corpus[idx]) <= max_length:\n",
    "                return corpus[idx]\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing corpus: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fe33015f-4cd6-4ad3-bc8f-debdb07354a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_fill = pd.read_csv('input_data/RACE_with_context_original.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dbe6a11f-0bd7-496f-86e5-d59dc3168c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_fill['E'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69e329d0-7131-4fd0-a5e7-b0522f964349",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = df_train_fill.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c81b932-75b0-4d15-a343-9d17dd1d0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming 'df' is your DataFrame and it has columns like 'option_A', 'option_B', etc.\n",
    "# all_options = pd.concat([dummy_df[f'{opt}'] for opt in ['A', 'B', 'C', 'D', 'E']])\n",
    "# unique_words = set()\n",
    "# for option in all_options.dropna():\n",
    "#     unique_words.update(option.split())\n",
    "\n",
    "# # This will be your dynamic vocab_list\n",
    "# vocab_list = list(unique_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3f7f9d19-4e83-41e6-9d12-9e1f5c2b7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "df_filled = df_train_fill.apply(fill_missing_sentence_options, axis=1)\n",
    "\n",
    "# dummy_df = df_train_fill.apply(fill_missing_options, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec8845d4-144a-48a9-848d-3dceab101149",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled.to_csv('./df_train_fill_RACE.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "70944307-fd81-4fd6-8678-c3064cdc68f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4d962f01-17d9-42c7-bd65-4f3dbf7334dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled_notnone = df_filled[~df_filled.E.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e55936e0-4273-45c0-ab29-78a8325fa425",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled_none = df_filled[df_filled.E.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ff7ed0e0-53b5-4202-af19-1dc6a4e217a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Loading the tokenizer from the `special_tokens_map.json` and the `added_tokens.json` will be removed in `transformers 5`,  it is kept for forward compatibility, but it is recommended to update your `tokenizer_config.json` by uploading it again. You will see the new `added_tokens_decoder` attribute that will store the relevant information.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = BertForMaskedLM.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def generate_option_using_bert(context, false_options, model, tokenizer):\n",
    "    # Create the prompt\n",
    "    prompt = f\"{context} Option A: {false_options[0]} Option B: {false_options[1]} Option C: {false_options[2]} The next false option is: [MASK].\"\n",
    "    \n",
    "    # Tokenize the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predictions = outputs.logits\n",
    "\n",
    "    # Get the predicted token for [MASK]\n",
    "    predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
    "    predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "\n",
    "    return predicted_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "127f83dc-607d-41ea-a1ab-6640746bc30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_sentence_options(row):\n",
    "    options = ['A', 'B', 'C', 'D', 'E']\n",
    "    correct_option = row['answer']\n",
    "\n",
    "    # Filter out the available incorrect options\n",
    "    incorrect_options = [row[opt] for opt in options if pd.notna(row[opt]) and opt != correct_option]\n",
    "\n",
    "    # If there's a missing option, generate it using BERT\n",
    "    if len(incorrect_options) == 3:\n",
    "        generated_option = generate_option_using_bert(row['context'], incorrect_options, model, tokenizer)\n",
    "        missing_option = list(set(options) - set([correct_option]) - set([k for k, v in row.items() if pd.notna(v)]))[0]\n",
    "        row[missing_option] = generated_option\n",
    "\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "579ee83a-3b91-40ab-b688-d1d373580693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = pd.read_csv('input_data/train_folds_article_context.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6213d86-58b7-43ba-92d0-da3cd03735c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'prompt', 'A', 'B', 'C', 'D', 'E', 'answer', 'kfold', 'context'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_old.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc8cd72c-f507-45ea-8bc8-9dc699fffa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_70k = pd.read_csv('input_data/len70021_with_context.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf81aab3-c328-4a75-9163-6f2b9cea7d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_70k.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cfe77f6e-be54-4913-a88e-37a5137921ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_70k = df_70k[['id', 'prompt', 'A', 'B', 'C', 'D', 'E', 'answer', 'context']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c6be9ef-9d36-4e96-95d8-dbd0c786f6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([df_old,df_70k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb4f7114-fe40-4d41-83e4-46d539672547",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['id'] =  range(len(df_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7e5e9072-a71b-4c04-bc6e-3378af83c0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_259652/3276211549.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filled_notnone['id'] = range(len(df_filled_notnone))\n"
     ]
    }
   ],
   "source": [
    "df_filled_notnone['id'] = range(len(df_filled_notnone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "27a3162a-a64a-4c75-be41-cd2797f46d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    39315\n",
       "2    16472\n",
       "1    16472\n",
       "0    16471\n",
       "Name: kfold, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.kfold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a8627cfb-801a-4a3e-9549-76408375b973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_259652/1011316941.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filled_notnone['kfold'] =3\n"
     ]
    }
   ],
   "source": [
    "df_filled_notnone['kfold'] =3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8e77516b-4da9-4cbe-b24a-a81a9e46056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_old,df_filled_notnone])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ebaf43c4-fe47-401c-88a3-bd7720e1f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('input_data/train_folds_article_context_added.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "63ed813f-0e58-419b-a9aa-7c419d1e300f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88730, 10)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4939ef41-57c3-46ce-895a-ed580dbfd868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "\n",
    "def create_folds(data, num_splits):\n",
    "    dfx = pd.get_dummies(data, columns=[\"answer\"]).groupby([\"id\"], as_index=False).sum()\n",
    "    cols = [c for c in dfx.columns if c.startswith(\"answer\") or c == \"id\" and c != \"answer\"]\n",
    "    dfx = dfx[cols]\n",
    "    \n",
    "    mskf = MultilabelStratifiedKFold(n_splits=num_splits, shuffle=True, random_state=42)\n",
    "    labels = [c for c in dfx.columns if c != \"id\"]\n",
    "    dfx_labels = dfx[labels]\n",
    "    dfx[\"kfold\"] = -1\n",
    "    \n",
    "    for fold, (trn_, val_) in enumerate(mskf.split(dfx, dfx_labels)):\n",
    "        dfx.loc[val_, \"kfold\"] = fold\n",
    "    \n",
    "    data = data.merge(dfx[[\"id\", \"kfold\"]], on=\"id\", how=\"left\")\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b66b9f84-3662-4d59-b158-5beb71877450",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all1 = create_folds(df_new, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9e7950a7-bc17-4a05-a125-cde0f654066f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    39775\n",
       "1    39774\n",
       "0    39774\n",
       "Name: kfold, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all1.kfold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49fd9394-effe-47ad-a448-2d3a283ae1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'prompt', 'A', 'B', 'C', 'D', 'E', 'answer', 'context', 'kfold'], dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fd814a54-de5e-40d1-a9fa-4f14082257c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all1.columns = ['id', 'prompt', 'A', 'B', 'C', 'D', 'E', 'answer', 'context',\n",
    "       'kfold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c8de090-0b0d-4011-b451-1afe0e2463f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all1.to_csv('input_data/train_folds_article_context_70+40.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f06d4a4a-fa52-4438-8718-279066362bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = df_filled_none.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "68011c4f-3fa6-4402-a8c5-1d7627e7f544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_filled_none1 = cc.apply(fill_missing_sentence_options, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f40c6531-b47f-4524-bb06-7e9ae00527ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>context</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>answer</th>\n",
       "      <th>is_question</th>\n",
       "      <th>dataset</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We can know from the passage that the author w...</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>doctor</td>\n",
       "      <td>model</td>\n",
       "      <td>teacher</td>\n",
       "      <td>reporter</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Many graduates today turn to cosmetic surgery ...</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>marry a better man/woman</td>\n",
       "      <td>become a model</td>\n",
       "      <td>get an advantage over others in job-hunting</td>\n",
       "      <td>attract more admirers</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What could be the best title for this passage?</td>\n",
       "      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n",
       "      <td>Death Toll Rises in an Accident in China</td>\n",
       "      <td>A Coal Mine Accident in Central China</td>\n",
       "      <td>An Accident in Central China</td>\n",
       "      <td>Coal Mine Accidents in China</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How many tips does the author give on career m...</td>\n",
       "      <td>Understanding the process of making career cho...</td>\n",
       "      <td>1.</td>\n",
       "      <td>2.</td>\n",
       "      <td>3.</td>\n",
       "      <td>4.</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Which of the following best describes the fami...</td>\n",
       "      <td>Astronauts on shorter shuttle missions often w...</td>\n",
       "      <td>They are caring and thoughtful.</td>\n",
       "      <td>They are worried and upset.</td>\n",
       "      <td>They are impatient and annoyed.</td>\n",
       "      <td>They are excited and curious.</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The passage mainly discusses how astronauts  _  .</td>\n",
       "      <td>Astronauts on shorter shuttle missions often w...</td>\n",
       "      <td>work for longer missions in space</td>\n",
       "      <td>connect with people on the Earth</td>\n",
       "      <td>spend their free time in space</td>\n",
       "      <td>observe the Earth from space</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>McCulloch and his group used_in their research.</td>\n",
       "      <td>Dogs have long been used to find explosives an...</td>\n",
       "      <td>10 dogs and 55 people</td>\n",
       "      <td>5 dogs and 86 people</td>\n",
       "      <td>10 dogs and 83 people</td>\n",
       "      <td>5 dogs and 169 people</td>\n",
       "      <td>D</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>We can infer from the passage that_.</td>\n",
       "      <td>Dogs have long been used to find explosives an...</td>\n",
       "      <td>dogs can smell signs of other cancers except t...</td>\n",
       "      <td>the final goal of the researchers is to design...</td>\n",
       "      <td>dogs can detect odors 10 000 to 100 000 times ...</td>\n",
       "      <td>dogs will soon be widely used to smell signs o...</td>\n",
       "      <td>B</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Which of the following would be the best title?</td>\n",
       "      <td>Dogs have long been used to find explosives an...</td>\n",
       "      <td>Special Noses of Dogs</td>\n",
       "      <td>Dogs and Cancer</td>\n",
       "      <td>Dogs Smell Signs of Cancer</td>\n",
       "      <td>McCulloch'S New Discovery</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>If you have free time only on Saturday, you ca...</td>\n",
       "      <td>Friends and Buddies\\nThis program is planned f...</td>\n",
       "      <td>Friends and Buddies</td>\n",
       "      <td>Club Saturday Swim</td>\n",
       "      <td>Sibshops (Ages 10-13)</td>\n",
       "      <td>Banana Splits</td>\n",
       "      <td>B</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prompt  \\\n",
       "0   We can know from the passage that the author w...   \n",
       "1   Many graduates today turn to cosmetic surgery ...   \n",
       "4      What could be the best title for this passage?   \n",
       "8   How many tips does the author give on career m...   \n",
       "11  Which of the following best describes the fami...   \n",
       "12  The passage mainly discusses how astronauts  _  .   \n",
       "13    McCulloch and his group used_in their research.   \n",
       "14               We can infer from the passage that_.   \n",
       "15    Which of the following would be the best title?   \n",
       "16  If you have free time only on Saturday, you ca...   \n",
       "\n",
       "                                              context  \\\n",
       "0   Last week I talked with some of my students ab...   \n",
       "1   Last week I talked with some of my students ab...   \n",
       "4   YUZHOU, HENAN -An accident in a central China ...   \n",
       "8   Understanding the process of making career cho...   \n",
       "11  Astronauts on shorter shuttle missions often w...   \n",
       "12  Astronauts on shorter shuttle missions often w...   \n",
       "13  Dogs have long been used to find explosives an...   \n",
       "14  Dogs have long been used to find explosives an...   \n",
       "15  Dogs have long been used to find explosives an...   \n",
       "16  Friends and Buddies\\nThis program is planned f...   \n",
       "\n",
       "                                                    A  \\\n",
       "0                                              doctor   \n",
       "1                            marry a better man/woman   \n",
       "4            Death Toll Rises in an Accident in China   \n",
       "8                                                  1.   \n",
       "11                    They are caring and thoughtful.   \n",
       "12                  work for longer missions in space   \n",
       "13                              10 dogs and 55 people   \n",
       "14  dogs can smell signs of other cancers except t...   \n",
       "15                              Special Noses of Dogs   \n",
       "16                                Friends and Buddies   \n",
       "\n",
       "                                                    B  \\\n",
       "0                                               model   \n",
       "1                                      become a model   \n",
       "4               A Coal Mine Accident in Central China   \n",
       "8                                                  2.   \n",
       "11                        They are worried and upset.   \n",
       "12                   connect with people on the Earth   \n",
       "13                               5 dogs and 86 people   \n",
       "14  the final goal of the researchers is to design...   \n",
       "15                                    Dogs and Cancer   \n",
       "16                                 Club Saturday Swim   \n",
       "\n",
       "                                                    C  \\\n",
       "0                                             teacher   \n",
       "1         get an advantage over others in job-hunting   \n",
       "4                        An Accident in Central China   \n",
       "8                                                  3.   \n",
       "11                    They are impatient and annoyed.   \n",
       "12                     spend their free time in space   \n",
       "13                              10 dogs and 83 people   \n",
       "14  dogs can detect odors 10 000 to 100 000 times ...   \n",
       "15                         Dogs Smell Signs of Cancer   \n",
       "16                              Sibshops (Ages 10-13)   \n",
       "\n",
       "                                                    D answer  is_question  \\\n",
       "0                                            reporter      C        False   \n",
       "1                               attract more admirers      C        False   \n",
       "4                        Coal Mine Accidents in China      B         True   \n",
       "8                                                  4.      D         True   \n",
       "11                      They are excited and curious.      A         True   \n",
       "12                       observe the Earth from space      C        False   \n",
       "13                              5 dogs and 169 people      D        False   \n",
       "14  dogs will soon be widely used to smell signs o...      B        False   \n",
       "15                          McCulloch'S New Discovery      C         True   \n",
       "16                                      Banana Splits      B        False   \n",
       "\n",
       "   dataset    E  \n",
       "0    train    .  \n",
       "1    train    .  \n",
       "4    train  the  \n",
       "8    train  you  \n",
       "11   train    .  \n",
       "12   train    .  \n",
       "13   train  the  \n",
       "14   train  the  \n",
       "15   train  the  \n",
       "16   train  the  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled_none1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b4d6c578-9e9a-42f6-8066-dcea2a63d316",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>context</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>answer</th>\n",
       "      <th>is_question</th>\n",
       "      <th>dataset</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We can know from the passage that the author w...</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>doctor</td>\n",
       "      <td>model</td>\n",
       "      <td>teacher</td>\n",
       "      <td>reporter</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Many graduates today turn to cosmetic surgery ...</td>\n",
       "      <td>Last week I talked with some of my students ab...</td>\n",
       "      <td>marry a better man/woman</td>\n",
       "      <td>become a model</td>\n",
       "      <td>get an advantage over others in job-hunting</td>\n",
       "      <td>attract more admirers</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What could be the best title for this passage?</td>\n",
       "      <td>YUZHOU, HENAN -An accident in a central China ...</td>\n",
       "      <td>Death Toll Rises in an Accident in China</td>\n",
       "      <td>A Coal Mine Accident in Central China</td>\n",
       "      <td>An Accident in Central China</td>\n",
       "      <td>Coal Mine Accidents in China</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How many tips does the author give on career m...</td>\n",
       "      <td>Understanding the process of making career cho...</td>\n",
       "      <td>1.</td>\n",
       "      <td>2.</td>\n",
       "      <td>3.</td>\n",
       "      <td>4.</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Which of the following best describes the fami...</td>\n",
       "      <td>Astronauts on shorter shuttle missions often w...</td>\n",
       "      <td>They are caring and thoughtful.</td>\n",
       "      <td>They are worried and upset.</td>\n",
       "      <td>They are impatient and annoyed.</td>\n",
       "      <td>They are excited and curious.</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97679</th>\n",
       "      <td>The writer might feel   _   before the Math Test.</td>\n",
       "      <td>One day in the eighth grade, I was taking a Ma...</td>\n",
       "      <td>surprised</td>\n",
       "      <td>relaxed</td>\n",
       "      <td>worried</td>\n",
       "      <td>excited</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97680</th>\n",
       "      <td>Which is the best expression to fill in the bl...</td>\n",
       "      <td>One day in the eighth grade, I was taking a Ma...</td>\n",
       "      <td>had breakfast</td>\n",
       "      <td>went to bed</td>\n",
       "      <td>took exercise</td>\n",
       "      <td>rode to school</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "      <td>test</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97681</th>\n",
       "      <td>The writer's father was   _  .</td>\n",
       "      <td>One day in the eighth grade, I was taking a Ma...</td>\n",
       "      <td>proud of him</td>\n",
       "      <td>tired of him</td>\n",
       "      <td>strict with him</td>\n",
       "      <td>pleased with him</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97682</th>\n",
       "      <td>From the passage, we know that the writer   _  .</td>\n",
       "      <td>One day in the eighth grade, I was taking a Ma...</td>\n",
       "      <td>could read Serbian</td>\n",
       "      <td>didn't cheat at last</td>\n",
       "      <td>got a good grade at last</td>\n",
       "      <td>didn't work hard that night</td>\n",
       "      <td>B</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97683</th>\n",
       "      <td>It takes   _   for the moon to go around the e...</td>\n",
       "      <td>When you look at the sky at night, the moon lo...</td>\n",
       "      <td>more than a week</td>\n",
       "      <td>nearly a month</td>\n",
       "      <td>half a year</td>\n",
       "      <td>more than a year</td>\n",
       "      <td>B</td>\n",
       "      <td>False</td>\n",
       "      <td>test</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58372 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  prompt  \\\n",
       "0      We can know from the passage that the author w...   \n",
       "1      Many graduates today turn to cosmetic surgery ...   \n",
       "4         What could be the best title for this passage?   \n",
       "8      How many tips does the author give on career m...   \n",
       "11     Which of the following best describes the fami...   \n",
       "...                                                  ...   \n",
       "97679  The writer might feel   _   before the Math Test.   \n",
       "97680  Which is the best expression to fill in the bl...   \n",
       "97681                     The writer's father was   _  .   \n",
       "97682   From the passage, we know that the writer   _  .   \n",
       "97683  It takes   _   for the moon to go around the e...   \n",
       "\n",
       "                                                 context  \\\n",
       "0      Last week I talked with some of my students ab...   \n",
       "1      Last week I talked with some of my students ab...   \n",
       "4      YUZHOU, HENAN -An accident in a central China ...   \n",
       "8      Understanding the process of making career cho...   \n",
       "11     Astronauts on shorter shuttle missions often w...   \n",
       "...                                                  ...   \n",
       "97679  One day in the eighth grade, I was taking a Ma...   \n",
       "97680  One day in the eighth grade, I was taking a Ma...   \n",
       "97681  One day in the eighth grade, I was taking a Ma...   \n",
       "97682  One day in the eighth grade, I was taking a Ma...   \n",
       "97683  When you look at the sky at night, the moon lo...   \n",
       "\n",
       "                                              A  \\\n",
       "0                                        doctor   \n",
       "1                      marry a better man/woman   \n",
       "4      Death Toll Rises in an Accident in China   \n",
       "8                                            1.   \n",
       "11              They are caring and thoughtful.   \n",
       "...                                         ...   \n",
       "97679                                 surprised   \n",
       "97680                             had breakfast   \n",
       "97681                              proud of him   \n",
       "97682                        could read Serbian   \n",
       "97683                          more than a week   \n",
       "\n",
       "                                           B  \\\n",
       "0                                      model   \n",
       "1                             become a model   \n",
       "4      A Coal Mine Accident in Central China   \n",
       "8                                         2.   \n",
       "11               They are worried and upset.   \n",
       "...                                      ...   \n",
       "97679                                relaxed   \n",
       "97680                            went to bed   \n",
       "97681                           tired of him   \n",
       "97682                   didn't cheat at last   \n",
       "97683                         nearly a month   \n",
       "\n",
       "                                                 C  \\\n",
       "0                                          teacher   \n",
       "1      get an advantage over others in job-hunting   \n",
       "4                     An Accident in Central China   \n",
       "8                                               3.   \n",
       "11                 They are impatient and annoyed.   \n",
       "...                                            ...   \n",
       "97679                                      worried   \n",
       "97680                                took exercise   \n",
       "97681                              strict with him   \n",
       "97682                     got a good grade at last   \n",
       "97683                                  half a year   \n",
       "\n",
       "                                   D answer  is_question dataset     E  \n",
       "0                           reporter      C        False   train  None  \n",
       "1              attract more admirers      C        False   train  None  \n",
       "4       Coal Mine Accidents in China      B         True   train  None  \n",
       "8                                 4.      D         True   train  None  \n",
       "11     They are excited and curious.      A         True   train  None  \n",
       "...                              ...    ...          ...     ...   ...  \n",
       "97679                        excited      C        False    test  None  \n",
       "97680                 rode to school      B         True    test  None  \n",
       "97681               pleased with him      C        False    test  None  \n",
       "97682    didn't work hard that night      B        False    test  None  \n",
       "97683               more than a year      B        False    test  None  \n",
       "\n",
       "[58372 rows x 10 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0781d7e9-02d7-4b4b-9fde-309fde19e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a3031c31-7f74-48b3-ad51-787af7cd1ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9618, 9), (13660, 9))"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df.dropna(how='any', axis=0).shape , dummy_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "4897a6b7-c3c8-4218-8b87-b38204193c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dummy_df  = dummy_df.dropna(how='any', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "c0601f73-41e6-4a69-9e0f-e87937629ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dummy_df.to_csv('./df_train_fill.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "71b98a3b-f844-4b2d-9868-3d95d4f85068",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dummy_df_fill = dummy_df[~dummy_df.id.isin(missing_dummy_df.id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "54ed7bda-2a68-4ef0-b98e-988bab5dc7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>context</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46688</th>\n",
       "      <td>What phenomenon makes global winds blow northe...</td>\n",
       "      <td>These winds blow predominantly from the northe...</td>\n",
       "      <td>muon effect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tropical effect</td>\n",
       "      <td>centrifugal effect</td>\n",
       "      <td>coriolis effect</td>\n",
       "      <td>E</td>\n",
       "      <td>46688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46690</th>\n",
       "      <td>What is the least dangerous radioactive decay?</td>\n",
       "      <td>If the beta decay of 222Rn is possible, it is ...</td>\n",
       "      <td>alpha decay</td>\n",
       "      <td>beta decay</td>\n",
       "      <td>zeta decay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gamma decay</td>\n",
       "      <td>A</td>\n",
       "      <td>46690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46693</th>\n",
       "      <td>What kind of a reaction occurs when a substanc...</td>\n",
       "      <td>The direct reaction of O2 with fuel is preclud...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>invention reaction</td>\n",
       "      <td>Fluid Reaction</td>\n",
       "      <td>nitrogen reaction</td>\n",
       "      <td>combustion reaction</td>\n",
       "      <td>E</td>\n",
       "      <td>46693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46694</th>\n",
       "      <td>Organisms categorized by what species descript...</td>\n",
       "      <td>It can be distinguished from allopatric specia...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>species complex</td>\n",
       "      <td>surface species</td>\n",
       "      <td>ring species</td>\n",
       "      <td>fitting species</td>\n",
       "      <td>D</td>\n",
       "      <td>46694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46697</th>\n",
       "      <td>Zinc is more easily oxidized than iron because...</td>\n",
       "      <td>Zinc is more reactive than iron or steel and t...</td>\n",
       "      <td>much metal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>active metal</td>\n",
       "      <td>Trap metal</td>\n",
       "      <td>usually metal</td>\n",
       "      <td>C</td>\n",
       "      <td>46697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60337</th>\n",
       "      <td>Animal claws, spines, and shells are examples ...</td>\n",
       "      <td>Since survival behaviours are so vital for an ...</td>\n",
       "      <td>defense mechanism</td>\n",
       "      <td>display behavior</td>\n",
       "      <td>learned behavior</td>\n",
       "      <td>spontaneous mutation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>60337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60338</th>\n",
       "      <td>The jejunum is about 0.9 meters (3 feet) long ...</td>\n",
       "      <td>* The jejunum is typically of larger diameter ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>black at death</td>\n",
       "      <td>empty at death</td>\n",
       "      <td>time.the at death</td>\n",
       "      <td>weeks at death</td>\n",
       "      <td>C</td>\n",
       "      <td>60338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60341</th>\n",
       "      <td>What is the number waves that pass a fixed poi...</td>\n",
       "      <td>If there is a periodic travelling wave solutio...</td>\n",
       "      <td>combination frequency</td>\n",
       "      <td>heating frequency</td>\n",
       "      <td>wave tendency</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wave frequency</td>\n",
       "      <td>E</td>\n",
       "      <td>60341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60345</th>\n",
       "      <td>Melting glaciers, rising temperatures and drou...</td>\n",
       "      <td>Impacts include changes in regional rainfall p...</td>\n",
       "      <td>nature's natural cycle</td>\n",
       "      <td>air pollution</td>\n",
       "      <td>global warming</td>\n",
       "      <td>sudden warming</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>60345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60346</th>\n",
       "      <td>What parts of a human possess the highest conc...</td>\n",
       "      <td>In thermoregulation, body heat is generated mo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hand and ears</td>\n",
       "      <td>face and hair</td>\n",
       "      <td>face and ears</td>\n",
       "      <td>hands and feet</td>\n",
       "      <td>D</td>\n",
       "      <td>60346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4042 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  prompt  \\\n",
       "46688  What phenomenon makes global winds blow northe...   \n",
       "46690     What is the least dangerous radioactive decay?   \n",
       "46693  What kind of a reaction occurs when a substanc...   \n",
       "46694  Organisms categorized by what species descript...   \n",
       "46697  Zinc is more easily oxidized than iron because...   \n",
       "...                                                  ...   \n",
       "60337  Animal claws, spines, and shells are examples ...   \n",
       "60338  The jejunum is about 0.9 meters (3 feet) long ...   \n",
       "60341  What is the number waves that pass a fixed poi...   \n",
       "60345  Melting glaciers, rising temperatures and drou...   \n",
       "60346  What parts of a human possess the highest conc...   \n",
       "\n",
       "                                                 context  \\\n",
       "46688  These winds blow predominantly from the northe...   \n",
       "46690  If the beta decay of 222Rn is possible, it is ...   \n",
       "46693  The direct reaction of O2 with fuel is preclud...   \n",
       "46694  It can be distinguished from allopatric specia...   \n",
       "46697  Zinc is more reactive than iron or steel and t...   \n",
       "...                                                  ...   \n",
       "60337  Since survival behaviours are so vital for an ...   \n",
       "60338  * The jejunum is typically of larger diameter ...   \n",
       "60341  If there is a periodic travelling wave solutio...   \n",
       "60345  Impacts include changes in regional rainfall p...   \n",
       "60346  In thermoregulation, body heat is generated mo...   \n",
       "\n",
       "                            A                   B                 C  \\\n",
       "46688             muon effect                 NaN   tropical effect   \n",
       "46690             alpha decay          beta decay        zeta decay   \n",
       "46693                     NaN  invention reaction    Fluid Reaction   \n",
       "46694                     NaN     species complex   surface species   \n",
       "46697              much metal                 NaN      active metal   \n",
       "...                       ...                 ...               ...   \n",
       "60337       defense mechanism    display behavior  learned behavior   \n",
       "60338                     NaN      black at death    empty at death   \n",
       "60341   combination frequency   heating frequency     wave tendency   \n",
       "60345  nature's natural cycle       air pollution    global warming   \n",
       "60346                     NaN       hand and ears     face and hair   \n",
       "\n",
       "                          D                    E answer     id  \n",
       "46688    centrifugal effect      coriolis effect      E  46688  \n",
       "46690                   NaN          gamma decay      A  46690  \n",
       "46693     nitrogen reaction  combustion reaction      E  46693  \n",
       "46694          ring species      fitting species      D  46694  \n",
       "46697            Trap metal        usually metal      C  46697  \n",
       "...                     ...                  ...    ...    ...  \n",
       "60337  spontaneous mutation                  NaN      A  60337  \n",
       "60338     time.the at death       weeks at death      C  60338  \n",
       "60341                   NaN       wave frequency      E  60341  \n",
       "60345        sudden warming                  NaN      C  60345  \n",
       "60346         face and ears       hands and feet      D  60346  \n",
       "\n",
       "[4042 rows x 9 columns]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_dummy_df_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "2c18e181-0ebd-490e-8450-109f03c33685",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dummy_df_fill[['prompt','A', 'B', 'C', 'D', 'E', 'answer', 'id']].to_csv('./missing_complex_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "7c2e085c-7c2e-4595-b302-a296b16bc4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_options_complex_cases(row):\n",
    "    options = ['A', 'B', 'C', 'D', 'E']\n",
    "    available_options = {opt: row[f'{opt}'] for opt in options if pd.notna(row[f'{opt}'])}\n",
    "    \n",
    "    # Remove the correct answer from available options\n",
    "    correct_option = row['answer']\n",
    "    available_options.pop(correct_option, None)\n",
    "    \n",
    "    # Generate similar words for available incorrect options\n",
    "    similar_words_list = []\n",
    "    for option_word in available_options.values():\n",
    "        # Considering only the last word in the phrase\n",
    "        option_last_word = option_word.split()[-1]\n",
    "        try:\n",
    "            similar_words = [item[0].replace('_', ' ') for item in model.most_similar(option_last_word, topn=3)]\n",
    "            for word in similar_words:\n",
    "                # Prepending with the original prefix to create a similar phrase\n",
    "                similar_phrase = option_word.replace(option_last_word, word)\n",
    "                similar_words_list.append(similar_phrase)\n",
    "        except KeyError:  # Skip words not in vocabulary\n",
    "            continue\n",
    "\n",
    "    random.shuffle(similar_words_list)\n",
    "    \n",
    "    # Fill missing options\n",
    "    for opt in options:\n",
    "        if pd.isna(row[f'{opt}']):\n",
    "            if similar_words_list:\n",
    "                row[f'{opt}'] = similar_words_list.pop(0)\n",
    "    \n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d51ea9-bf41-4b98-9db6-375fd6b390e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dummy_df_fill = missing_dummy_df_fill.apply(fill_missing_options_complex_cases, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "f87158de-1399-4e07-9bb8-2ebea37bdcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['prompt', 'context', 'A', 'B', 'C', 'D', 'E', 'answer', 'id'], dtype='object')"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_dummy_df_fill.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1535c8d6-113a-4ade-880f-5912f105a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dummy_df_fill.to_csv('./df_train_fill_complex.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "2dd7ad2c-f4a3-49a9-a367-00a0a254ac9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>context</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46688</th>\n",
       "      <td>What phenomenon makes global winds blow northe...</td>\n",
       "      <td>These winds blow predominantly from the northe...</td>\n",
       "      <td>muon effect</td>\n",
       "      <td>tropical impact</td>\n",
       "      <td>tropical effect</td>\n",
       "      <td>centrifugal effect</td>\n",
       "      <td>coriolis effect</td>\n",
       "      <td>E</td>\n",
       "      <td>46688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46690</th>\n",
       "      <td>What is the least dangerous radioactive decay?</td>\n",
       "      <td>If the beta decay of 222Rn is possible, it is ...</td>\n",
       "      <td>alpha decay</td>\n",
       "      <td>beta decay</td>\n",
       "      <td>zeta decay</td>\n",
       "      <td>beta degeneration</td>\n",
       "      <td>gamma decay</td>\n",
       "      <td>A</td>\n",
       "      <td>46690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46693</th>\n",
       "      <td>What kind of a reaction occurs when a substanc...</td>\n",
       "      <td>The direct reaction of O2 with fuel is preclud...</td>\n",
       "      <td>Fluid reactions</td>\n",
       "      <td>invention reaction</td>\n",
       "      <td>Fluid Reaction</td>\n",
       "      <td>nitrogen reaction</td>\n",
       "      <td>combustion reaction</td>\n",
       "      <td>E</td>\n",
       "      <td>46693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46694</th>\n",
       "      <td>Organisms categorized by what species descript...</td>\n",
       "      <td>It can be distinguished from allopatric specia...</td>\n",
       "      <td>surface vertebrate species</td>\n",
       "      <td>species complex</td>\n",
       "      <td>surface species</td>\n",
       "      <td>ring species</td>\n",
       "      <td>fitting species</td>\n",
       "      <td>D</td>\n",
       "      <td>46694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46697</th>\n",
       "      <td>Zinc is more easily oxidized than iron because...</td>\n",
       "      <td>Zinc is more reactive than iron or steel and t...</td>\n",
       "      <td>much metal</td>\n",
       "      <td>much Metal</td>\n",
       "      <td>active metal</td>\n",
       "      <td>Trap metal</td>\n",
       "      <td>usually metal</td>\n",
       "      <td>C</td>\n",
       "      <td>46697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60337</th>\n",
       "      <td>Animal claws, spines, and shells are examples ...</td>\n",
       "      <td>Since survival behaviours are so vital for an ...</td>\n",
       "      <td>defense mechanism</td>\n",
       "      <td>display behavior</td>\n",
       "      <td>learned behavior</td>\n",
       "      <td>spontaneous mutation</td>\n",
       "      <td>display behavious</td>\n",
       "      <td>A</td>\n",
       "      <td>60337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60338</th>\n",
       "      <td>The jejunum is about 0.9 meters (3 feet) long ...</td>\n",
       "      <td>* The jejunum is typically of larger diameter ...</td>\n",
       "      <td>black at deaths</td>\n",
       "      <td>black at death</td>\n",
       "      <td>empty at death</td>\n",
       "      <td>time.the at death</td>\n",
       "      <td>weeks at death</td>\n",
       "      <td>C</td>\n",
       "      <td>60338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60341</th>\n",
       "      <td>What is the number waves that pass a fixed poi...</td>\n",
       "      <td>If there is a periodic travelling wave solutio...</td>\n",
       "      <td>combination frequency</td>\n",
       "      <td>heating frequency</td>\n",
       "      <td>wave tendency</td>\n",
       "      <td>heating ####.# MHz</td>\n",
       "      <td>wave frequency</td>\n",
       "      <td>E</td>\n",
       "      <td>60341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60345</th>\n",
       "      <td>Melting glaciers, rising temperatures and drou...</td>\n",
       "      <td>Impacts include changes in regional rainfall p...</td>\n",
       "      <td>nature's natural cycle</td>\n",
       "      <td>air pollution</td>\n",
       "      <td>global warming</td>\n",
       "      <td>sudden warming</td>\n",
       "      <td>air air pollution</td>\n",
       "      <td>C</td>\n",
       "      <td>60345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60346</th>\n",
       "      <td>What parts of a human possess the highest conc...</td>\n",
       "      <td>In thermoregulation, body heat is generated mo...</td>\n",
       "      <td>face and curly hair</td>\n",
       "      <td>hand and ears</td>\n",
       "      <td>face and hair</td>\n",
       "      <td>face and ears</td>\n",
       "      <td>hands and feet</td>\n",
       "      <td>D</td>\n",
       "      <td>60346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4042 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  prompt  \\\n",
       "46688  What phenomenon makes global winds blow northe...   \n",
       "46690     What is the least dangerous radioactive decay?   \n",
       "46693  What kind of a reaction occurs when a substanc...   \n",
       "46694  Organisms categorized by what species descript...   \n",
       "46697  Zinc is more easily oxidized than iron because...   \n",
       "...                                                  ...   \n",
       "60337  Animal claws, spines, and shells are examples ...   \n",
       "60338  The jejunum is about 0.9 meters (3 feet) long ...   \n",
       "60341  What is the number waves that pass a fixed poi...   \n",
       "60345  Melting glaciers, rising temperatures and drou...   \n",
       "60346  What parts of a human possess the highest conc...   \n",
       "\n",
       "                                                 context  \\\n",
       "46688  These winds blow predominantly from the northe...   \n",
       "46690  If the beta decay of 222Rn is possible, it is ...   \n",
       "46693  The direct reaction of O2 with fuel is preclud...   \n",
       "46694  It can be distinguished from allopatric specia...   \n",
       "46697  Zinc is more reactive than iron or steel and t...   \n",
       "...                                                  ...   \n",
       "60337  Since survival behaviours are so vital for an ...   \n",
       "60338  * The jejunum is typically of larger diameter ...   \n",
       "60341  If there is a periodic travelling wave solutio...   \n",
       "60345  Impacts include changes in regional rainfall p...   \n",
       "60346  In thermoregulation, body heat is generated mo...   \n",
       "\n",
       "                                A                   B                 C  \\\n",
       "46688                 muon effect     tropical impact   tropical effect   \n",
       "46690                 alpha decay          beta decay        zeta decay   \n",
       "46693             Fluid reactions  invention reaction    Fluid Reaction   \n",
       "46694  surface vertebrate species     species complex   surface species   \n",
       "46697                  much metal          much Metal      active metal   \n",
       "...                           ...                 ...               ...   \n",
       "60337           defense mechanism    display behavior  learned behavior   \n",
       "60338             black at deaths      black at death    empty at death   \n",
       "60341       combination frequency   heating frequency     wave tendency   \n",
       "60345      nature's natural cycle       air pollution    global warming   \n",
       "60346         face and curly hair       hand and ears     face and hair   \n",
       "\n",
       "                          D                    E answer     id  \n",
       "46688    centrifugal effect      coriolis effect      E  46688  \n",
       "46690     beta degeneration          gamma decay      A  46690  \n",
       "46693     nitrogen reaction  combustion reaction      E  46693  \n",
       "46694          ring species      fitting species      D  46694  \n",
       "46697            Trap metal        usually metal      C  46697  \n",
       "...                     ...                  ...    ...    ...  \n",
       "60337  spontaneous mutation    display behavious      A  60337  \n",
       "60338     time.the at death       weeks at death      C  60338  \n",
       "60341    heating ####.# MHz       wave frequency      E  60341  \n",
       "60345        sudden warming    air air pollution      C  60345  \n",
       "60346         face and ears       hands and feet      D  60346  \n",
       "\n",
       "[4042 rows x 9 columns]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_dummy_df_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "8f2ca23e-2362-474e-b258-25c8d441bde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3915, 9)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_dummy_df_fill.dropna(how='any', axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6d08adb-189b-4617-ad44-3b709c34e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cntx = 'MOND is an example of a class of theories known as modified gravity, and is an alternative to the hypothesis that the dynamics of galaxies are determined by massive, invisible dark matter halos. Since Milgrom\\'s original proposal, proponents of MOND have claimed to successfully predict a variety of galactic phenomena that they state are difficult to understand as consequences of dark matter.Though MOND explains the anomalously great rotational velocities of galaxies at their perimeters, it does not fully explain the velocity dispersions of individual galaxies within galaxy clusters. MOND reduces the discrepancy between the velocity dispersions and clusters\\' observed missing baryonic mass from a factor of around 10 to a factor of about 2. However, the residual discrepancy cannot be accounted for by MOND, requiring that other explanations close the gap such as the presence of as-yet undetected missing baryonic matter.The accurate measurement of the speed of gravitational waves compared to the speed of light in 2017 ruled out a certain class of modified gravity theories but concluded that other MOND theories that dispense with the need for dark matter remained viable. Two years later, theories put forth by Constantinos Skordis and Tom Zlosnik were consistent with gravitational waves that always travel at the speed of light. Later still in 2021, Skordis and Zlosnik developed a subclass of their theory called \"RMOND\", for \"relativistic MOND\", which had \"been shown to reproduce in great detail the main observations in cosmology, including the cosmic-microwave-background power spectrum, and the matter structure power spectrum.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b9d0af5-de6b-4334-9404-cea8b39b3560",
   "metadata": {},
   "outputs": [],
   "source": [
    "cntx = 'Outstanding problems for MOND The most serious problem facing Milgrom\\'s law is that it cannot eliminate the need for dark matter in all astrophysical systems: galaxy clusters show a residual mass discrepancy even when analyzed using MOND. The fact that some form of unseen mass must exist in these systems detracts from the adequacy of MOND as a solution to the missing mass problem, although the amount of extra mass required is a fifth that of a Newtonian analysis, and there is no requirement that the missing mass be non-baryonic. It has been speculated that 2 eV neutrinos could account for the cluster observations in MOND while preserving the hypothesis\\'s successes at the galaxy scale. Indeed, analysis of sharp lensing data for the galaxy cluster Abell 1689 shows that MOND only becomes distinctive at Mpc distance from the center, so that Zwicky\\'s conundrum remains, and 1.8 eV neutrinos are needed in clusters.The 2006 observation of a pair of colliding galaxy clusters known as the \"Bullet Cluster\", poses a significant challenge for all theories proposing a modified gravity solution to the missing mass problem, including MOND. Astronomers measured the distribution of stellar and gas mass in the clusters using visible and X-ray light, respectively, and in addition mapped the inferred dark matter density using gravitational lensing. In MOND, one would expect the \"missing mass\" to be centred on regions of visible mass which experience accelerations lower than a0 (assuming the external field effect is negligible). In ΛCDM, on the other hand, one would expect the dark matter to be significantly offset from the visible mass because the halos of the two colliding clusters would pass through each other (assuming, as is conventional, that dark matter is collisionless), whilst the cluster gas would interact and end up at the centre. An offset is clearly seen in the observations. It has been suggested, however, that MOND-based models may be able to generate such an offset in strongly non-spherically symmetric systems, such as the Bullet Cluster.A significant piece of evidence in favor of standard dark matter is the observed anisotropies in the cosmic microwave background. While ΛCDM is able to explain the observed angular power spectrum, MOND has a much harder time, though recently it has been shown that MOND can fit the observations too. MOND also encounters difficulties explaining structure formation, with density perturbations in MOND perhaps growing so rapidly that too much structure is formed by the present epoch. However, forming galaxies more rapidly than in ΛCDM can be a good thing to some extent.Several other studies have noted observational difficulties with MOND. For example, it has been claimed that MOND offers a poor fit to the velocity dispersion profile of globular clusters and the temperature profile of galaxy clusters, that different values of a0 are required for agreement with different galaxies\\' rotation curves, and that MOND is naturally unsuited to forming the basis of cosmology. Furthermore, many versions of MOND predict that the speed of light is different from the speed of gravity, but in 2017 the speed of gravitational waves was measured to be equal to the speed of light to high precision. This is well understood in modern relativistic theories of MOND, with the constraint from gravitational waves actually helping by substantially restricting how a covariant theory might be constructed.Besides these observational issues, MOND and its relativistic generalizations are plagued by theoretical difficulties. Several ad hoc and inelegant additions to general relativity are required to create a theory compatible with a non-Newtonian non-relativistic limit, though the predictions in this limit are rather clear. This is the case for the more commonly used modified gravity versions of MOND, but some formulations (most prominently those based on modified inertia) have long suffered from poor compatibility with cherished physical principles such as conservation laws. Researchers working on MOND generally do not interpret it as a modification of inertia, with only very limited work done on this area.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49235b73-080c-4905-b34a-6bcc5ea66a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4174"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cntx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "124fe9f9-16fa-4459-b93c-67fa6fd8190b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Outstanding problems for MOND The most serious problem facing Milgrom\\'s law is that it cannot eliminate the need for dark matter in all astrophysical systems: galaxy clusters show a residual mass discrepancy even when analyzed using MOND. The fact that some form of unseen mass must exist in these systems detracts from the adequacy of MOND as a solution to the missing mass problem, although the amount of extra mass required is a fifth that of a Newtonian analysis, and there is no requirement that the missing mass be non-baryonic. It has been speculated that 2 eV neutrinos could account for the cluster observations in MOND while preserving the hypothesis\\'s successes at the galaxy scale. Indeed, analysis of sharp lensing data for the galaxy cluster Abell 1689 shows that MOND only becomes distinctive at Mpc distance from the center, so that Zwicky\\'s conundrum remains, and 1.8 eV neutrinos are needed in clusters.The 2006 observation of a pair of colliding galaxy clusters known as the \"Bullet Cluster\", poses a significant challenge for all theories proposing a modified gravity solution to the missing mass problem, including MOND. Astronomers measured the distribution of stellar and gas mass in the clusters using visible and X-ray light, respectively, and in addition mapped the inferred dark matter density using gravitational lensing. In MOND, one would expect the \"missing mass\" to be centred on regions of visible mass which experience accelerations lower than a0 (assuming the external field effect is negligible). In ΛCDM, on the other hand, one would expect the dark matter to be significantly offset from the visible mass because the halos of the two colliding clusters would pass through each other (assuming, as is conventional, that dark matter is collisionless), whilst the cluster gas would interact and end up at the centre. An offset is clearly seen in the observations. It has been suggested, however, that MOND-based models may be able to generate such an offset in strongly non-spherically symmetric systems, such as the Bullet Cluster.A significant piece of evidence in favor of standard dark matter is the observed anisotropies in the cosmic microwave background. While ΛCDM is able to explain the observed angular power spectrum, MOND has a much harder time, though recently it has been shown that MOND can fit the observations too. MOND also encounters difficulties explaining structure formation, with density perturbations in MOND perhaps growing so rapidly that '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cntx[:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff0ccc3b-5b09-4b24-bc2f-9c46a8a53ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"too much structure is formed by the present epoch. However, forming galaxies more rapidly than in ΛCDM can be a good thing to some extent.Several other studies have noted observational difficulties with MOND. For example, it has been claimed that MOND offers a poor fit to the velocity dispersion profile of globular clusters and the temperature profile of galaxy clusters, that different values of a0 are required for agreement with different galaxies' rotation curves, and that MOND is naturally unsuited to forming the basis of cosmology. Furthermore, many versions of MOND predict that the speed of light is different from the speed of gravity, but in 2017 the speed of gravitational waves was measured to be equal to the speed of light to high precision. This is well understood in modern relativistic theories of MOND, with the constraint from gravitational waves actually helping by substantially restricting how a covariant theory might be constructed.Besides these observational issues, MOND and its relativistic generalizations are plagued by theoretical difficulties. Several ad hoc and inelegant additions to general relativity are required to create a theory compatible with a non-Newtonian non-relativistic limit, though the predictions in this limit are rather clear. This is the case for the more commonly used modified gravity versions of MOND, but some formulations (most prominently those based on modified inertia) have long suffered from poor compatibility with cherished physical principles such as conservation laws. Researchers working on MOND generally do not interpret it as a modification of inertia, with only very limited work done on this area.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cntx[2500:4200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe581212-9cb4-4832-bed3-fb6499982cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(index, row, tokenizer, retrieved_articles_parsed):\n",
    "        system_prefix = \"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n{instruction}\\n\\n### Input:\\n{input_prefix}\"\n",
    "        instruction = f\"Your task is to analyze the question and answer below. If the answer is correct, respond yes, if it is not correct respond no. As a potential aid to your answer, background context from Wikipedia articles is at your disposal, even if they might not always be pertinent.\"\n",
    "        wiki_context = f\"{retrieved_articles_parsed[index][-3][2]}\\n{retrieved_articles_parsed[index][-2][2]}\\n{retrieved_articles_parsed[index][-1][2]}\" \n",
    "#         context1 = f\"{retrieved_articles[index][-4][2]}\\n{retrieved_articles[index][-3][2]}\\n{retrieved_articles[index][-2][2]}\\n{retrieved_articles[index][-1][2]}\"\n",
    "        input_prefix = f\"Context: {wiki_context[:MAX_CONTEXT]}\\nQuestion: {row['prompt']}\\nProposed answer: \"\n",
    "        prompt_prefix = system_prefix.format(instruction=instruction, input_prefix=input_prefix)\n",
    "        prefix = tokenizer(prompt_prefix, return_tensors=\"pt\", return_attention_mask=False, truncation=True, max_length=MAX_LENGTH)['input_ids']\n",
    "        prompt_suffix = [f\"{row[letter]}\\n\\n### Response:\\n\" for letter in 'ABCDE']\n",
    "        suffix = tokenizer(prompt_suffix, return_tensors=\"pt\", return_attention_mask=False, truncation=True, max_length=MAX_LENGTH, padding=True)['input_ids'][:, 1:]\n",
    "        return prefix, suffix \n",
    "    \n",
    "    \n",
    "\n",
    "def run_model(device, df):\n",
    "    model = ShardedLlama(checkpoint_path, device=f'cuda:{device}')\n",
    "    inputs = df.reset_index().apply(lambda row: get_tokens(row['index'], row, tokenizer=model.tokenizer, retrieved_articles_parsed=retrieved_articles_parsed), axis=1).values\n",
    "    batches = np.array_split(inputs, N_BATCHES)\n",
    "    outputs = []\n",
    "    for batch in batches:\n",
    "        outputs += model(batch, output_token=4874)\n",
    "    return outputs\n",
    "\n",
    "# Run model\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    outputs = list(executor.map(run_model, [0, 1], np.array_split(df, 2)))\n",
    "    outputs = sum(outputs, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d185dea-8ae7-49ab-a4b9-b52277eadbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d172b5f-a7d6-43de-a493-9bdfa5a73e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(row, tokenizer):\n",
    "    context = row['context'][:MAX_CONTEXT]\n",
    "    prompt = row['prompt']\n",
    "    \n",
    "    # Create a key for the cache\n",
    "    cache_key = f\"context:{context}_prompt:{prompt}\"\n",
    "    \n",
    "    if cache_key in tokenized_cache:\n",
    "        return tokenized_cache[cache_key]\n",
    "    \n",
    "    # ... Your existing tokenization code ...\n",
    "    \n",
    "    prefix, suffix = tokenizer(prompt_prefix, return_tensors=\"pt\", return_attention_mask=False, truncation=True, max_length=MAX_LENGTH)[\"input_ids\"], tokenizer(prompt_suffix, return_tensors=\"pt\", return_attention_mask=False, truncation=True, max_length=MAX_LENGTH, padding=True)[\"input_ids\"][:, 1:]\n",
    "    \n",
    "    # Store tokenized output in the cache\n",
    "    tokenized_cache[cache_key] = (prefix, suffix)\n",
    "    \n",
    "    return prefix, suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e786814c-b29d-4d41-baf0-fe7091cc41ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "1e267295-0a6f-4fab-8177-d4b5d6c8752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor([3, 0, 3, 3, 0, 4, 3, 0, 3, 4, 4, 3])\n",
    "\n",
    "y_preds = torch.tensor([[ 0.0809,  0.1396, -0.0039,  0.1592,  0.0755],\n",
    "        [ 0.0881,  0.1466, -0.0024,  0.1619,  0.0827],\n",
    "        [ 0.0910,  0.1463,  0.0056,  0.1694,  0.0862],\n",
    "        [ 0.0878,  0.1381, -0.0026,  0.1658,  0.0776],\n",
    "        [ 0.0795,  0.1336, -0.0080,  0.1588,  0.0768],\n",
    "        [ 0.0787,  0.1359, -0.0029,  0.1639,  0.0768],\n",
    "        [ 0.0841,  0.1335, -0.0039,  0.1603,  0.0808],\n",
    "        [ 0.0921,  0.1506,  0.0006,  0.1663,  0.0889],\n",
    "        [ 0.0819,  0.1423, -0.0025,  0.1623,  0.0814],\n",
    "        [ 0.0825,  0.1419, -0.0056,  0.1591,  0.0781],\n",
    "        [ 0.0906,  0.1427, -0.0031,  0.1647,  0.0822],\n",
    "        [ 0.0837,  0.1398, -0.0032,  0.1606,  0.0798]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0cd2bc1e-480d-4ae5-b8d8-508d3393ed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_indices = labels.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8248bd99-d469-4c0e-88c9-eb9178a2fa14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 3, 3, 0, 4, 3, 0, 3, 4, 4, 3])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2faa2b80-afde-4bbc-823a-4c408a44e076",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_scores = y_preds[torch.arange(y_preds.size(0)), correct_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8e80737d-fa16-4a1b-a737-38fa5e6dea7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1592, 0.0881, 0.1694, 0.1658, 0.0795, 0.0768, 0.1603, 0.0921, 0.1623,\n",
       "        0.0781, 0.0822, 0.1606])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca0db83-9eae-401d-b00f-0b7311e8c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_scores = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8aca5e13-717e-4811-8418-cd452e1d6d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a mask\n",
    "mask = torch.ones(y_preds.shape, dtype=torch.bool)\n",
    "mask[torch.arange(y_preds.size(0)), correct_indices] = 0\n",
    "\n",
    "# Step 2: Use this mask to select the scores associated with the incorrect labels\n",
    "negative_scores_all = y_preds[mask].view(y_preds.size(0), -1)\n",
    "\n",
    "# Step 3: If you just want one negative score (maximum) for each instance\n",
    "max_negative_scores = negative_scores_all.max(dim=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6b25705c-7c36-4fdd-9d80-6167c7ba6f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1396, 0.1619, 0.1463, 0.1381, 0.1588, 0.1639, 0.1335, 0.1663, 0.1423,\n",
       "        0.1591, 0.1647, 0.1398])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_negative_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1b43f927-56e9-4447-bd77-b5e74e031497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0809,  0.1396, -0.0039,  0.0755],\n",
       "        [ 0.1466, -0.0024,  0.1619,  0.0827],\n",
       "        [ 0.0910,  0.1463,  0.0056,  0.0862],\n",
       "        [ 0.0878,  0.1381, -0.0026,  0.0776],\n",
       "        [ 0.1336, -0.0080,  0.1588,  0.0768],\n",
       "        [ 0.0787,  0.1359, -0.0029,  0.1639],\n",
       "        [ 0.0841,  0.1335, -0.0039,  0.0808],\n",
       "        [ 0.1506,  0.0006,  0.1663,  0.0889],\n",
       "        [ 0.0819,  0.1423, -0.0025,  0.0814],\n",
       "        [ 0.0825,  0.1419, -0.0056,  0.1591],\n",
       "        [ 0.0906,  0.1427, -0.0031,  0.1647],\n",
       "        [ 0.0837,  0.1398, -0.0032,  0.0798]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_scores_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "07abe36d-a641-4460-86e1-eeaf277018d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1396, 0.1619, 0.1463, 0.1381, 0.1588, 0.1639, 0.1335, 0.1663, 0.1423,\n",
       "         0.1591, 0.1647, 0.1398]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_negative_scores.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835bf86f-fff2-430b-8856-0c762f776b7a",
   "metadata": {},
   "source": [
    "#### Check Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "91fa8594-5458-475a-a27d-4b519df15982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import Optional, Union\n",
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aa1aa086-8ee0-4246-86f7-41000d5eba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6c1dc22d-cde5-48f6-b4e9-09062c90cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_INPUT= 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "45d76ae1-e229-4573-8424-38a6aaacdf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_answering_input_deberta(\n",
    "        tokenizer, # longformer_tokenizer\n",
    "        question,  # str\n",
    "        options,   # List[str]\n",
    "        context,   # str\n",
    "        max_seq_length=4096,\n",
    "    ):\n",
    "    \n",
    "    first_sentence = [ \"[CLS] \" + context ] * 5\n",
    "    second_sentences = [\" #### \" + question + \" [SEP] \" + option + \" [SEP]\" for option in options]\n",
    "    tokenized_examples = tokenizer(first_sentence, second_sentences, truncation='only_first', \n",
    "                                  max_length=max_seq_length, add_special_tokens=False)\n",
    "      \n",
    "\n",
    "    return tokenized_examples\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class LlmseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, is_train=False, aug_prob=0.8):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.is_train = is_train\n",
    "        self.aug_prob = aug_prob\n",
    "        self.option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        example = self.df.iloc[idx]\n",
    "        tokenized_example = dict()\n",
    "        \n",
    "        if self.is_train and torch.rand(1)<self.aug_prob:\n",
    "            prm = torch.randperm(5).numpy()\n",
    "\n",
    "            \n",
    "            permed_a2e = np.array(['A','B','C','D','E'])[prm]\n",
    "            permed_dict_a2p = {a: p for p, a in enumerate(permed_a2e)}\n",
    "            \n",
    "            # options = [ example[option] + \" [SEP]\" for option in permed_a2e] # for longformer\n",
    "            options = [ example[option] for option in permed_a2e] \n",
    "            \n",
    "\n",
    "            tokenized_example = prepare_answering_input_deberta(tokenizer=self.tokenizer, question=example['prompt'], options=options, context= example['context'], max_seq_length = MAX_INPUT)\n",
    "            \n",
    "\n",
    "            tokenized_example['label'] = permed_dict_a2p[example['answer']]\n",
    "\n",
    "            \n",
    "        else:\n",
    "\n",
    "            options = [ example[option] for option in 'ABCDE']\n",
    "            # tokenized_example = prepare_answering_input(tokenizer=self.tokenizer, question=example['prompt'], options=options, context= example['context'], max_seq_length = config.MAX_INPUT )\n",
    "        \n",
    "            tokenized_example = prepare_answering_input_deberta(tokenizer=self.tokenizer, question=example['prompt'], options=options, context= example['context'], max_seq_length = MAX_INPUT )\n",
    "            \n",
    "            tokenized_example['label'] = self.option_to_index[example['answer']]\n",
    "\n",
    "        return tokenized_example\n",
    "            \n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    \n",
    "    def __call__(self, features):\n",
    "        label_name = 'label' if 'label' in features[0].keys() else 'labels'\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0]['input_ids'])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "946df5da-44f1-4c46-b057-5b16befb2bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= pd.read_csv('input_data/train_folds_article_context_70+40.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "89fc8c4b-621d-4b78-87ac-33879df47ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['len_context'] = train_df['context'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c0077a2b-b714-41c3-b65e-678716a81ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/workspace/.local/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('models/microsoft/deberta-v3-large/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d61460f9-8e35-46b5-995b-b7a28d69e713",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_df[train_df.len_context >4000].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e10e6a70-ee6d-482c-97cc-260e708ac5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = LlmseDataset(train_set, tokenizer, is_train=True, aug_prob=1.0)\n",
    "data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\n",
    "train_dataloader = DataLoader(\n",
    "        train_ds, \n",
    "        batch_size=5, \n",
    "        shuffle=True, \n",
    "        collate_fn=data_collator,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "256608b3-80a8-47f5-be76-7fc3fca30a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "cc = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9608c68c-4d18-46dc-8039-1d8ef6ff24e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     1,    341, 119524,  ...,    268,    260,      2],\n",
       "        [     1,    341, 119524,  ...,    260,    309,      2],\n",
       "        [     1,    341, 119524,  ...,   3389,    260,      2],\n",
       "        [     1,    341, 119524,  ...,    912,    260,      2],\n",
       "        [     1,    341, 119524,  ...,    268,    260,      2]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc['input_ids'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "50155676-1bcd-4028-b603-a78651fb1f96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1,\n",
       "       'How does Modified Newtonian Dynamics (MOND) impact the observed \"missing baryonic mass\" discrepancy in galaxy clusters, according to the provided excerpt from Wikipedia?',\n",
       "       'MOND is a theory that increases the discrepancy between the observed missing baryonic mass in galaxy clusters and the measured velocity dispersions.',\n",
       "       'MOND explains the missing baryonic mass in galaxy clusters that was previously considered dark matter by demonstrating that the mass is in the form of neutrinos and axions.',\n",
       "       'MOND is a theory that reduces the observed missing baryonic mass in galaxy clusters by postulating the existence of a new form of matter called \"fuzzy dark matter.\"',\n",
       "       'MOND is a theory that eliminates the observed missing baryonic mass in galaxy clusters by imposing a new mathematical formulation of gravity that does not require the existence of dark matter.',\n",
       "       \"MOND's impact on the observed missing baryonic mass in galaxy clusters remains a subject of debate.\",\n",
       "       'E',\n",
       "       '-Modified Newtonian dynamics (MOND) is a hypothesis that proposes a modification of Newton\\'s law of universal gravitation to account for observed properties of galaxies. It is an alternative to the hypothesis of dark matter in terms of explaining why galaxies do not appear to obey the currently understood laws of physics.\\n-MOND is an example of a class of theories known as modified gravity, and is an alternative to the hypothesis that the dynamics of galaxies are determined by massive, invisible dark matter halos. Since Milgrom\\'s original proposal, proponents of MOND have claimed to successfully predict a variety of galactic phenomena that they state are difficult to understand as consequences of dark matter.Though MOND explains the anomalously great rotational velocities of galaxies at their perimeters, it does not fully explain the velocity dispersions of individual galaxies within galaxy clusters. MOND reduces the discrepancy between the velocity dispersions and clusters\\' observed missing baryonic mass from a factor of around 10 to a factor of about 2. However, the residual discrepancy cannot be accounted for by MOND, requiring that other explanations close the gap such as the presence of as-yet undetected missing baryonic matter.The accurate measurement of the speed of gravitational waves compared to the speed of light in 2017 ruled out a certain class of modified gravity theories but concluded that other MOND theories that dispense with the need for dark matter remained viable. Two years later, theories put forth by Constantinos Skordis and Tom Zlosnik were consistent with gravitational waves that always travel at the speed of light. Later still in 2021, Skordis and Zlosnik developed a subclass of their theory called \"RMOND\", for \"relativistic MOND\", which had \"been shown to reproduce in great detail the main observations in cosmology, including the cosmic-microwave-background power spectrum, and the matter structure power spectrum.\" \\n-MOND Modified Newtonian Dynamics (MOND) is a relatively modern proposal to explain the galaxy rotation problem based on a variation of Newton\\'s Second Law of Dynamics at low accelerations. This would produce a large-scale variation of Newton\\'s universal theory of gravity. A modification of Newton\\'s theory would also imply a modification of general relativistic cosmology in as much as Newtonian cosmology is the limit of Friedman cosmology. While almost all astrophysicists today reject MOND in favor of dark matter, a small number of researchers continue to enhance it, recently incorporating Brans–Dicke theories into treatments that attempt to account for cosmological observations.\\n-Outstanding problems for MOND The most serious problem facing Milgrom\\'s law is that it cannot eliminate the need for dark matter in all astrophysical systems: galaxy clusters show a residual mass discrepancy even when analyzed using MOND. The fact that some form of unseen mass must exist in these systems detracts from the adequacy of MOND as a solution to the missing mass problem, although the amount of extra mass required is a fifth that of a Newtonian analysis, and there is no requirement that the missing mass be non-baryonic. It has been speculated that 2 eV neutrinos could account for the cluster observations in MOND while preserving the hypothesis\\'s successes at the galaxy scale. Indeed, analysis of sharp lensing data for the galaxy cluster Abell 1689 shows that MOND only becomes distinctive at Mpc distance from the center, so that Zwicky\\'s conundrum remains, and 1.8 eV neutrinos are needed in clusters.The 2006 observation of a pair of colliding galaxy clusters known as the \"Bullet Cluster\", poses a significant challenge for all theories proposing a modified gravity solution to the missing mass problem, including MOND. Astronomers measured the distribution of stellar and gas mass in the clusters using visible and X-ray light, respectively, and in addition mapped the inferred dark matter density using gravitational lensing. In MOND, one would expect the \"missing mass\" to be centred on regions of visible mass which experience accelerations lower than a0 (assuming the external field effect is negligible). In ΛCDM, on the other hand, one would expect the dark matter to be significantly offset from the visible mass because the halos of the two colliding clusters would pass through each other (assuming, as is conventional, that dark matter is collisionless), whilst the cluster gas would interact and end up at the centre. An offset is clearly seen in the observations. It has been suggested, however, that MOND-based models may be able to generate such an offset in strongly non-spherically symmetric systems, such as the Bullet Cluster.A significant piece of evidence in favor of standard dark matter is the observed anisotropies in the cosmic microwave background. While ΛCDM is able to explain the observed angular power spectrum, MOND has a much harder time, though recently it has been shown that MOND can fit the observations too. MOND also encounters difficulties explaining structure formation, with density perturbations in MOND perhaps growing so rapidly that too much structure is formed by the present epoch. However, forming galaxies more rapidly than in ΛCDM can be a good thing to some extent.Several other studies have noted observational difficulties with MOND. For example, it has been claimed that MOND offers a poor fit to the velocity dispersion profile of globular clusters and the temperature profile of galaxy clusters, that different values of a0 are required for agreement with different galaxies\\' rotation curves, and that MOND is naturally unsuited to forming the basis of cosmology. Furthermore, many versions of MOND predict that the speed of light is different from the speed of gravity, but in 2017 the speed of gravitational waves was measured to be equal to the speed of light to high precision. This is well understood in modern relativistic theories of MOND, with the constraint from gravitational waves actually helping by substantially restricting how a covariant theory might be constructed.Besides these observational issues, MOND and its relativistic generalizations are plagued by theoretical difficulties. Several ad hoc and inelegant additions to general relativity are required to create a theory compatible with a non-Newtonian non-relativistic limit, though the predictions in this limit are rather clear. This is the case for the more commonly used modified gravity versions of MOND, but some formulations (most prominently those based on modified inertia) have long suffered from poor compatibility with cherished physical principles such as conservation laws. Researchers working on MOND generally do not interpret it as a modification of inertia, with only very limited work done on this area.\\n-There have been a number of attempts to solve the problem of galaxy rotation by modifying gravity without invoking dark matter. One of the most discussed is modified Newtonian dynamics (MOND), originally proposed by Mordehai Milgrom in 1983, which modifies the Newtonian force law at low accelerations to enhance the effective gravitational attraction. MOND has had a considerable amount of success in predicting the rotation curves of low-surface-brightness galaxies, matching the baryonic Tully–Fisher relation, and the velocity dispersions of the small satellite galaxies of the Local Group.Using data from the Spitzer Photometry and Accurate Rotation Curves (SPARC) database, a group has found that the radial acceleration traced by rotation curves could be predicted just from the observed baryon distribution (that is, including stars and gas but not dark matter). The same relation provided a good fit for 2693 samples in 153 rotating galaxies, with diverse shapes, masses, sizes, and gas fractions. Brightness in the near infrared, where the more stable light from red giants dominates, was used to estimate the density contribution due to stars more consistently. The results are consistent with MOND, and place limits on alternative explanations involving dark matter alone. However, cosmological simulations within a Lambda-CDM framework that include baryonic feedback effects reproduce the same relation, without the need to invoke new dynamics (such as MOND). Thus, a contribution due to dark matter itself can be fully predictable from that of the baryons, once the feedback effects due to the dissipative collapse of baryons are taken into account. MOND is not a relativistic theory, although relativistic theories which reduce to MOND have been proposed, such as tensor–vector–scalar gravity (TeVeS), scalar–tensor–vector gravity (STVG), the f(R) theory of Capozziello and De Laurentis, not to mention a version of Superfluid Vacuum theory based on the Logarithmic Schrödinger equation.A model of galaxy based on a general relativity metric was also proposed, showing that the rotation curves for the Milky Way, NGC 3031, NGC 3198 and NGC 7331 are consistent with the mass density distributions of the visible matter, avoiding the need for a massive halo of exotic dark matter.According to a 2020 analysis of the data produced by the Gaia spacecraft, it would seem possible to explain at least the Milky Way\\'s rotation curve without requiring any dark matter if instead of a Newtonian approximation the entire set of equations of general relativity is adopted.In March 2021, Gerson Otto Ludwig published a model based on general relativity that explains galaxy rotation curves with gravitoelectromagnetism.',\n",
       "       1, 9562], dtype=object)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.iloc[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26c2089-d864-4bf3-be4e-345846700ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "01cb9904-79c3-4906-ab46-577bd437061f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] -Modified Newtonian dynamics (MOND) is a hypothesis that proposes a modification of Newton\\'s law of universal gravitation to account for observed properties of galaxies. It is an alternative to the hypothesis of dark matter in terms of explaining why galaxies do not appear to obey the currently understood laws of physics. -MOND is an example of a class of theories known as modified gravity, and is an alternative to the hypothesis that the dynamics of galaxies are determined by massive, invisible dark matter halos. Since Milgrom\\'s original proposal, proponents of MOND have claimed to successfully predict a variety of galactic phenomena that they state are difficult to understand as consequences of dark matter.Though MOND explains the anomalously great rotational velocities of galaxies at their perimeters, it does not fully explain the velocity dispersions of individual galaxies within galaxy clusters. MOND reduces the discrepancy between the velocity dispersions and clusters\\' observed missing baryonic mass from a factor of around 10 to a factor of about 2. However, the residual discrepancy cannot be accounted for by MOND, requiring that other explanations close the gap such as the presence of as-yet undetected missing baryonic matter.The accurate measurement of the speed of gravitational waves compared to the speed of light in 2017 ruled out a certain class of modified gravity theories but concluded that other MOND theories that dispense with the need for dark matter remained viable. Two years later, theories put forth by Constantinos Skordis and Tom Zlosnik were consistent with gravitational waves that always travel at the speed of light. Later still in 2021, Skordis and Zlosnik developed a subclass of their theory called \"RMOND\", for \"relativistic MOND\", which had \"been shown to reproduce in great detail the main observations in cosmology, including the cosmic-microwave-background power spectrum, and the matter structure power spectrum.\" -MOND Modified Newtonian Dynamics (MOND) is a relatively modern proposal to explain the galaxy rotation problem based on a variation of Newton\\'s Second Law of Dynamics at low accelerations. This would produce a large-scale variation of Newton\\'s universal theory of gravity. A modification of Newton\\'s theory would also imply a modification of general relativistic cosmology in as much as Newtonian cosmology is the limit of Friedman cosmology. While almost all astrophysicists today reject MOND in favor of dark matter, a small number of researchers continue to enhance it, recently incorporating Brans–Dicke theories into treatments that attempt to account for cosmological observations. -Outstanding problems for MOND The most serious problem facing Milgrom\\'s law is that it cannot eliminate the need for dark matter in all astrophysical systems: galaxy clusters show a residual mass discrepancy even when analyzed using MOND. The fact that some form of unseen mass must exist in these systems detracts from the adequacy of MOND as a solution to the missing mass problem, although the amount of extra mass required is a fifth that of a Newtonian analysis, and there is no requirement that the missing mass be non-baryonic. It has been speculated that 2 eV neutrinos could account for the cluster observations in MOND while preserving the hypothesis\\'s successes at the galaxy scale. Indeed, analysis of sharp lensing data for the galaxy cluster Abell 1689 shows that MOND only becomes distinctive at Mpc distance from the center, so that Zwicky\\'s conundrum remains, and 1.8 eV neutrinos are needed in clusters.The 2006 observation of a pair of colliding galaxy clusters known #### How does Modified Newtonian Dynamics (MOND) impact the observed \"missing baryonic mass\" discrepancy in galaxy clusters, according to the provided excerpt from Wikipedia?[SEP] MOND explains the missing baryonic mass in galaxy clusters that was previously considered dark matter by demonstrating that the mass is in the form of neutrinos and axions.[SEP]'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(cc['input_ids'][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "caf74343-b60d-4ae9-b8a9-bdfec4eaf726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] -Modified Newtonian dynamics (MOND) is a hypothesis that proposes a modification of Newton's law of universal gravitation to account for observed properties of galaxies. It is an alternative to the hypothesis of dark matter in terms of explaining why galaxies do not appear to obey the currently understood laws of physics. -MOND is an example of a class of theories known as modified gravity, and is an alternative to the hypothesis that the dynamics of galaxies are determined by massive, invisible dark matter halos. Since Milgrom's original proposal, proponents of MOND have claimed to successfully predict a variety of galactic phenomena that they state are difficult to understand as consequences of dark matter.Though MOND explains the anomalously great rotational velocities of galaxies at their perimeters, it does not fully explain the velocity dispersions of individual galaxies within galaxy clusters. MOND reduces the discrepancy between the velocity dispersions and clusters' observed missing baryonic mass from a factor of around 10 to a factor of about 2. However, the residual discrepancy cannot be accounted for by MOND, requiring that other explanations close the gap such as the presence of as-yet undetected missing baryonic matter.The accurate measurement of the speed of gravitational waves compared to the speed of light in 2017 ruled out a certain class of modified gravity theories but concluded that other MOND theories that dispense with the need for dark matter remained viable. Two years later, theories put forth by Constantinos Skordis and Tom Zlosnik were consistent with gravitational waves that always travel at the speed of light. Later still in 2021, Skordis and Zlosnik developed a subclass of their theory called \"RMOND\", for \"relativistic MOND\", which had \"been shown to reproduce in great detail the main observations in cosmology, including the cosmic-microwave-background power spectrum, and the matter structure power spectrum.\" -MOND Modified Newtonian Dynamics (MOND) is a relatively modern proposal to explain the galaxy rotation problem based on a variation of Newton's Second Law of Dynamics at low accelerations. This would produce a large-scale variation of Newton's universal theory of gravity. A modification of Newton's theory would also imply a modification of general relativistic cosmology in as much as Newtonian cosmology is the limit of Friedman cosmology. While almost all astrophysicists today reject MOND in favor of dark matter, a small number of researchers continue to enhance it, recently incorporating Brans–Dicke theories into treatments that attempt to account for cosmological observations. -Outstanding problems for MOND The most serious problem facing Milgrom's law is that it cannot eliminate the need for dark matter in all astrophysical systems: galaxy clusters show a residual mass discrepancy even when analyzed using MOND. The fact that some form of unseen mass must exist in these systems detracts from the adequacy of MOND as a solution to the missing mass problem, although the amount of extra mass required is a fifth that of a Newtonian analysis, and there is no requirement that the missing mass be non-baryonic. It has been speculated that 2 eV neutrinos could account for the cluster observations in MOND while preserving the hypothesis's successes at the galaxy scale. Indeed, analysis of sharp lensing data for the galaxy cluster Abell 1689 shows that MOND only becomes distinctive at Mpc distance from the center, so that Zwicky's conundrum remains, and 1.8 eV neutrinos are needed in clusters.The 2006 observation of a pair of colliding galaxy clusters #### How does Modified Newtonian Dynamics (MOND) impact the observed \"missing baryonic mass\" discrepancy in galaxy clusters, according to the provided excerpt from Wikipedia?[SEP] MOND is a theory that reduces the observed missing baryonic mass in galaxy clusters by postulating the existence of a new form of matter called \"fuzzy dark matter.\"[SEP]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(cc['input_ids'][1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5332975-7f16-4062-b657-0cfe4de76f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
